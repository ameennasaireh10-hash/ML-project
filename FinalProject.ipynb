{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ac008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mglearn as mg\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline , make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder , StandardScaler , LabelEncoder , OrdinalEncoder  \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier , KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split , KFold , cross_val_score , GridSearchCV\n",
    "from sklearn.linear_model import Lasso , LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sb\n",
    "import category_encoders as ce\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29378f98",
   "metadata": {},
   "source": [
    "0: reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6535d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "aisles = pd.read_csv(r\"archive\\aisles.csv\")\n",
    "department = pd.read_csv(r\"archive\\departments.csv\")\n",
    "pro_prior = pd.read_csv(r\"archive\\order_products__prior.csv\")\n",
    "pro_train = pd.read_csv(r\"archive/order_products__train.csv\")\n",
    "orders = pd.read_csv(r\"archive\\orders.csv\")\n",
    "products = pd.read_csv(r\"archive\\products.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb53e77",
   "metadata": {},
   "source": [
    "1: Joins and memory optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b03abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if \"int\" in str(col_type):                 #السترينق حطيتها لانه برجع np.dtype ف لازم نحولها لنوعها المنطقي عشان نقدر نعمل مقارنه\n",
    "            df[col] = df[col].astype(\"int32\")\n",
    "\n",
    "        elif \"float\" in str(col_type):\n",
    "            df[col] = df[col].astype(\"float32\")\n",
    "\n",
    "        #بالبدايه حطيت بس else بعدين اكتشفت انه في انواع بيانات ثانيه مثل bool\n",
    "        elif col_type == \"object\":\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8d6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = [aisles , department , pro_prior , pro_train , orders , products]\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i] = reduce_memory(dfs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   في m1 \n",
    "#   pro_prior بلشنا ب هذول لانه يحتوي تفاصيل المنتجات داخل الطلبات\n",
    "#   orders هو اللي بحتوي على معلومات الطلب , المستخدم , الوقت\n",
    "m1 = pd.merge(pro_prior , orders , on = \"order_id\" , how = \"left\")\n",
    "m2 = pd.merge(m1 , products , on = \"product_id\" , how = \"left\")\n",
    "m3 = pd.merge(m2 , department , on = \"department_id\" , how = \"left\")\n",
    "Full_DataSet = pd.merge(m3 , aisles , on = \"aisle_id\" , how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c2a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Full_DataSet.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db0c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#كنت بدي اصير اعمل قراءه للملف مره ثانيه عشان ما اضل اعمل دمج كل ما اشغل الكود , بس اكتشفت انه تحميله بقعد وقت اكثر\n",
    "#Full_DataSet.to_csv('archive/full_instacart_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c4665",
   "metadata": {},
   "source": [
    "2: EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cheking for null values\n",
    "missing_values = Full_DataSet.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print( missing_values )\n",
    "print(\"==\"*40 )\n",
    "missing_percent = (missing_values / len(Full_DataSet)) * 100\n",
    "print(f\"Percentage of missing values in columns\\n {missing_percent}\", )\n",
    "\n",
    "missing_percent.plot(kind='bar', figsize=(8, 5), width=0.3, color='red', rot=0)\n",
    "plt.ylabel(\"Missing Percentage\")\n",
    "plt.title(\"Missing Values Percentage per Feature\")\n",
    "plt.show()\n",
    "# هاي مش قيم مفقوده بالغلط هاي بتدل انه الزبون اول مره بيطلب فمفيش عندو قيمه ل days_since_prior_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fbfa82",
   "metadata": {},
   "source": [
    "Distribution plots for numeric features and target(s) (histogram, density).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a2dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# لازم نختار الاعمده الرقميه الي الها معنى او بتفيدنا لو عملنا الها هستوغرام او دينستي بالاحرى مين مهم افهم الديستربويشن تبعو\n",
    "Full_DataSet['order_hour_of_day'].plot(kind='hist', bins=24, figsize=(10, 6), title='Distribution of Orders by Hour of Day')\n",
    "\n",
    "#Histogram (المدرج التكراري) رسمة أعمدة بتبين الكمية في كل فترة\n",
    "\n",
    "plt.xlabel('Hour of Day (0 - 23)') # سمينا المحور عشان الدكتور يفهم\n",
    "\n",
    "plt.ylabel('Frequency (Number of Orders)')\n",
    "plt.show()\n",
    "\n",
    "#بنلاحظ  فوق الوقت الي بكون فيه وقت الذروه للزباين متى بكون باليوم "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9dc89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_DataSet['days_since_prior_order'].plot(kind='hist', bins=30, figsize=(7, 6), color='orange', title='Distribution of Days Since Prior Order')\n",
    "\n",
    "plt.xlabel('Days Since Last Order')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b1c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weekly shoppers (peak at 7 days) and Monthly shoppers (peak at 30 days). The spike at 30 days also includes customers who haven't ordered for more than a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91573d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. نأخذ عينة عشوائية (10% مثلاً) عشان الرام ما تنفجر\n",
    "# هذا العمود يمثل \"ساعات اليوم\" من 0 لـ 23\n",
    "sample_hours = Full_DataSet['order_hour_of_day'].sample(frac=0.1, random_state=42)\n",
    "\n",
    "# 2. الرسم\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sample_hours.plot(kind='kde', color='green', title='Density Plot of Order Hour of Day')\n",
    "\n",
    "plt.xlabel('Hour of Day (0-23)')\n",
    "plt.xlim(0, 23) # عشان نحصر الرسمة في حدود اليوم\n",
    "plt.show()\n",
    "\n",
    "#الدينستي بعطينا هون تفاصيل اكثر او معبر اكثر بس بوخذ وقت اكثر للامانه \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9815cbf8",
   "metadata": {},
   "source": [
    "Categorical cardinality analysis (barplots / top-k frequencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21bba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to do some cardinality checking for the catorgorical features\n",
    "categorical_cols = Full_DataSet.select_dtypes(include=['category']).columns\n",
    "categorical_cols\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983a57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_DataSet[\"product_name\"].value_counts() # هون بنلاحظ انو في منتجات كتير متكرره يعني الكارديناليتي عاليه فهاض العامود مابفيدني اعملو فيجواليزشن"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a96f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# نعمل فحص للباقي \n",
    "checking = ['department', 'aisle', 'product_name']\n",
    "\n",
    "cardinality_counts = Full_DataSet[checking].nunique()\n",
    "print(\"عدد الأنواع في كل عمود\")\n",
    "print(cardinality_counts)\n",
    "# هون بنلاحظ الديبراتمنت فيه تنوع واطي فا بنقدر نعملو فيجواليز ونستفيد منه \n",
    "# الممرات 134 يعتبر عاللي فامبنقدر نرسمو كلو رح نوخذ الاكثر تكرارا تمام نفس الحاله بنطبقها على اسماء المنتجات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is eval_set refer to ? \n",
    "Full_DataSet['eval_set'].value_counts()\n",
    "# هون شفنا انو هاض العامود بحتوي على داتا بتمثل الطلبات القديمه فهاض الاشي مابفيدني اني اعملو فيجواليز "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  بنرسمه كأعمدة Barplot\n",
    "Full_DataSet['department'].value_counts().plot(kind='bar', figsize=(12,6) , color='blue')\n",
    "\n",
    "plt.title('Total Orders per Department', fontsize=15)\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xlabel('Department Name')\n",
    "plt.xticks(rotation=45, ha='right') # ميلنا الأسماء عشان نقرأها بوضوح\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670448a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_aisles = Full_DataSet['aisle'].value_counts().head(25)\n",
    "#  هون ممكن تسالني انت طيب كيف رتبتهم من الاكثر للاقل ؟ لان الميثود تاعت الفاليوز بالديفولت تاعها بترتبهم من الاكبر لاصغبر \n",
    "\n",
    "top_aisles.plot(kind='bar',figsize=(12, 6), color='blue')\n",
    "\n",
    "\n",
    "plt.title('Top 25 Best Selling aisles ', fontsize=14)\n",
    "plt.ylabel('Number of Orders')\n",
    "plt.xlabel('Aisle Name')\n",
    "plt.xticks(rotation=45, ha='right') # ميلنا الكلام بزاوية 45 عشان ينقرأ بوضوح\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf6739",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_for_visuals = Full_DataSet['product_name'].value_counts().head(20) # هون اخذنا اكثر 20 بس عشان يصير مقروء بشكل احسن \n",
    "\n",
    "products_for_visuals.plot(kind='bar', figsize=(12, 6), color='blue')\n",
    "plt.title('Top 25 Best Selling Products ', fontsize=14)\n",
    "plt.ylabel('Number of Orders')  \n",
    "plt.xlabel('Product Name')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677155a",
   "metadata": {},
   "source": [
    "• Correlation matrix, heatmap and pairwise scatter plots for selected numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  هاي الخطوة بدنا نعرف شو العوامل اللي بتخلي الزبون يعمل اعادة طلب او reorder\n",
    "# في هاي الحاله لازم نختار الاعمده الرقميه الي الها سلوك او بمعنى اصح الها معنى "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'order_number',\n",
    "    'order_dow', \n",
    "    'order_hour_of_day', \n",
    "    'days_since_prior_order', \n",
    "    'add_to_cart_order', \n",
    "    'reordered' # هاض العامود الي بدنا نعرف شو العوامل الي بتأثر عليه مثل ماقلنا فوق \n",
    "]\n",
    "\n",
    "# 2. حساب المصفوفة (Correlation Matrix)\n",
    "# الدالة .corr() هي العقل المدبر اللي بيحسب العلاقات\n",
    "corr_matrix = Full_DataSet[selected_features].corr()\n",
    "\n",
    "\n",
    "# annot=True: عشان يكتب الرقم جوا المربع\n",
    "# cmap='coolwarm': ألوان (أحمر للحار/الموجب، أزرق للبارد/السالب)\n",
    "# fmt='.2f': منزلتين عشريتين بس\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=False)\n",
    "\n",
    "plt.title('Correlation Heatmap of Numeric Features', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b5667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. نأخذ عينة صغيرة جداً (1000 سطر) عشان الرسم يكون خفيف وواضح\n",
    "# Scatter Plot بيموت لو الداتا كبيرة\n",
    "scatter_sample = Full_DataSet.sample(n=1000, random_state=42)\n",
    "\n",
    "# 2. تحديد الأعمدة اللي بدنا نشوف علاقتها ببعض\n",
    "# ركزنا على أهم 3 أعمدة عشان ما نضيع وقت\n",
    "cols_to_plot = ['add_to_cart_order', 'days_since_prior_order', 'reordered']\n",
    "\n",
    "# 3. رسم الـ Pairplot\n",
    "# hue='reordered': عشان يلون النقاط (برتقالي للمكرر، أزرق للجديد)\n",
    "sns.pairplot(scatter_sample[cols_to_plot], hue='reordered', palette='husl', height=3)\n",
    "\n",
    "plt.suptitle('Pairwise Scatter Plots ', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70efd15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#طيب اللون الاخضر هون بمثل المنتجات المعاد شرائها بنلاحظ بالرسمه انو دايما بالبدايه ببدا الزبون يجيب اغراضو الي  متعود عليها\n",
    "#بعدين بعد ما يجيبهم بجيب او بجرب اغراض جديده  مثل مابثمل اللون الزهري الي بمثل الاشياء الجديده\n",
    "#الرسمة الشمال تحت النقط بتوريك إن المنتجات المكررة الخضراء دايما محجوز الها المقاعد الأولى بالسلة  بغض النظر عن كم يوم مر.\n",
    "\n",
    "# الرسمة اليمين جبال بتأكد إن الناس بتتسوق بنظام أسبوعي أو شهري والمنتجات الجديدة والقديمة بتمشي على نفس هذا النظام."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb4df0",
   "metadata": {},
   "source": [
    "• Time-of-day, day-of-week, and monthly seasonality plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb1c68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourrr=Full_DataSet['order_hour_of_day'].value_counts()\n",
    "hourrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff76183",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "\n",
    "# هون لازم قبل مانرسم نجهز الداتا لانها عباره عن مليون سطر فا لازم نرتبها اول حسب التكرار بعدين بنرتبها حسب الاندكس تصاعدني \n",
    "hour_counts = Full_DataSet['order_hour_of_day'].value_counts().sort_index()\n",
    "#لو تركناها هيك لاحظت رح تطلع معنا الرسمه الساعات من صفر ل 23 فا حيكون شوي مش مقروء الوضع فا افترحت لو بدنا نوري هالرسمه لاي حد لو نزبط الاندكس\n",
    "#ونخليه بنظام am و pm \n",
    "#بكون احسن ليش فقط عشان نخليه مقروء واريح للعين اكثر \n",
    "labels_of_hours = [\n",
    "    \"12 AM\", \"1 AM\", \"2 AM\", \"3 AM\", \"4 AM\", \"5 AM\", \n",
    "    \"6 AM\", \"7 AM\", \"8 AM\", \"9 AM\", \"10 AM\", \"11 AM\",\n",
    "    \"12 PM\", \"1 PM\", \"2 PM\", \"3 PM\", \"4 PM\", \"5 PM\", \n",
    "    \"6 PM\", \"7 PM\", \"8 PM\", \"9 PM\", \"10 PM\", \"11 PM\"\n",
    "]\n",
    "# x=labels_of_hours (الساعات)\n",
    "# y=hour_counts.values (عدد الطلبات)\n",
    "#هون اخترنا بار بلوت عشان سريع وبرضو برسملنا ال 24 عمود بسرعه عاليه\n",
    "sns.barplot(x=labels_of_hours, y=hour_counts.values, color='orange',)\n",
    "\n",
    "plt.title('Time of day Orders', fontsize=15)\n",
    "plt.xlabel('Hours: 12 AM - 11 PM  ', fontsize=12,color='blue') \n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# رح يطلع معنا 7 أرقام من 0 ـ 6\n",
    "day_counts = Full_DataSet['order_dow'].value_counts().sort_index()\n",
    "\n",
    "#بنرتبهم كمان مره زي ماعملنا فوق \n",
    " # الويك إند عند الاجانب ببدا من السبت فهو رح يكون رقم صفر\n",
    "days_labels = [\"Saturday\",  \"Sunday\", \"Monday\",  \"Tuesday\", \"Wednesday\", \"Thursday\",\"Friday \"]\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x=days_labels, y=day_counts.values, color=\"orange\")\n",
    "\n",
    "plt.title('Orders Day of Week ', fontsize=15)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xlabel('Day', fontsize=12)\n",
    "\n",
    "plt.show()\n",
    "#بنلاحظ انو بالويكند اعلى طلبات وهاض المنطقي لانو الناس بتكون معطله"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc960f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "#  هون رح نستخدم هاض الكولوم لانو انسب اشي للمنثلي لانو مافي عنا بالداتا سيت كولم عن الاشهر\n",
    "days_of_month_counts = Full_DataSet['days_since_prior_order'].value_counts().sort_index()\n",
    "#رح نستخدم اللاين بلوت عشان نوضح التغيرات بشكل افضل\n",
    "sns.lineplot(x=days_of_month_counts.index, y=days_of_month_counts.values, marker='o', color='red', linewidth=2)\n",
    "\n",
    "# 3. تحسين المحاور\n",
    "plt.title('Monthly Seasonality', fontsize=14)\n",
    "plt.xlabel('Days Since Last Order', fontsize=12)\n",
    "plt.ylabel('Number of Orders', fontsize=12)\n",
    "plt.show()\n",
    "#بنلاحظ في قمه عند ال 7 و 30 يوم هاض يعني انو الزبون كل اسبوع غالبا بيجي يشتري وفي زباين بتيجي كل شهر او اكثر من شهر هاض كلو بنحط عند ال 30 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9fcc4",
   "metadata": {},
   "source": [
    "3+4+5: cleaning , preprocessing and scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b6c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "del Full_DataSet[\"aisle\"]\n",
    "del Full_DataSet[\"department\"]\n",
    "del Full_DataSet[\"eval_set\"]\n",
    " \n",
    "print(Full_DataSet.isnull().sum())\n",
    "print(\"---------------------------------------\")\n",
    "\n",
    "#كان هدفي اشوف ال نان من هون بس ما زبطت ف شفتها من الملف نفسه\n",
    "Full_DataSet.head(10)\n",
    "#اللي بين معي انه ال نان بكون موجود لكل اول اوردير بطلبه المستخدم\\الزبون"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_outliers(Full_DataSet):\n",
    "\n",
    "    out = [\"order_id\" , \"product_id\" , \"user_id\" , \"aisle_id\" , \"department_id\" , \"eval_set\"]\n",
    "    Outliers_DF = []\n",
    "    numeric_cols_all = Full_DataSet.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "\n",
    "    for i in numeric_cols_all:\n",
    "        if i not in out:\n",
    "            Outliers_DF.append(i)\n",
    "              \n",
    "    col_length = len(Outliers_DF)\n",
    "    row = (col_length // 3) + 1\n",
    "    plt.figure(figsize=(20 , 5 * row))\n",
    "\n",
    "    for i , col in enumerate(Outliers_DF):\n",
    "        plt.subplot(row , 3 , i + 1)\n",
    "            \n",
    "        plot_data = Full_DataSet[col].dropna().sample(n = min(100000 , len(Full_DataSet)))\n",
    "            \n",
    "        sb.boxplot(x = plot_data , color=\"lightblue\")\n",
    "        plt.title(col , fontsize = 12)\n",
    "        plt.xlabel(\" \")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45b92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_outliers(Full_DataSet))\n",
    "\n",
    "#من القيم اللي حسبتها بالاضافه للرسم , بين معي انه بعد ال30 بتصير عندي نبسة التكرارات قليله مقارنة بالباقي ف اخترتها تكون حد فاصل \n",
    "Full_DataSet[\"add_to_cart_order\"] =  np.where(Full_DataSet[\"add_to_cart_order\"] > 30 , 30 , Full_DataSet[\"add_to_cart_order\"])\n",
    "Full_DataSet[\"order_number\"] =  np.where(Full_DataSet[\"order_number\"] > 50 , 50 , Full_DataSet[\"order_number\"])\n",
    "\n",
    "print(Full_DataSet[\"add_to_cart_order\"].describe())\n",
    "print()\n",
    "print(Full_DataSet[\"order_number\"].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb379afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Full_DataSet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e13178",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = \"constant\" , fill_value = 0)\n",
    "#بعد ما تفرجت عالداتا من الاكسل , اكتشفت انه النان موجوده بس عند اول طلب للمستخدم , يعني ما هنده طلب مسبق\n",
    "#الموديل لما يشوف الصفر رح يقلك هاض المستخدم جديد , وعشان هيك ما عنده طلبات مسبقه\n",
    "Full_DataSet[\"days_since_prior_order\"] = imputer.fit_transform(Full_DataSet[\"days_since_prior_order\"].values.reshape(-1,1))\n",
    "\n",
    "DF = pd.DataFrame(Full_DataSet , columns = Full_DataSet.columns)\n",
    "\n",
    "#DF.to_csv('archive/full_instacart_data.csv', index=False)\n",
    "print(DF.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b307e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_params_for_TE(DF , high_cols):\n",
    "\n",
    "    #المشكله اللي صارت انه لما اقسم الداتا , لسا ما شغل البريبروسيسر عليها ف لسا مش كل الفيتشرز تحولو لقيم رقميه\n",
    "    del DF[\"product_name\"]\n",
    "\n",
    "    unique_users = DF['user_id'].unique()\n",
    "    selected_users = np.random.choice(unique_users, size=3000, replace=False)\n",
    "    #رفعت عدد العينات ل 5000 والكود طول لتنه اشتغل ف عشان هيك قللتهم ك حل وسط وهون طلع معي افضل نتيجع بعد عدة تكرارات\n",
    "\n",
    "    df_check = DF[DF['user_id'].isin(selected_users)].copy()\n",
    "\n",
    "    df_check[high_cols] = df_check[high_cols].astype(str)\n",
    "\n",
    "    xc = df_check.drop(\"reordered\", axis=1)\n",
    "    yc = df_check['reordered']\n",
    "\n",
    "    xc_train , xc_test , yc_train , yc_test = train_test_split(xc , yc , test_size = 0.2 , random_state = 42)\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        ce.TargetEncoder(cols=high_cols) , \n",
    "        RandomForestClassifier(\n",
    "            n_estimators = 100,  # عدد الأشجار\n",
    "            max_depth = 10 ,      # عمق الشجرة (عشان ما ياخذ وقت طويل)\n",
    "            random_state = 42 ,\n",
    "            n_jobs = -1          # تشغيل كل المعالجات\n",
    "        )\n",
    "    )\n",
    "\n",
    "    param_grid = {\n",
    "        'targetencoder__smoothing': [1, 10, 50] ,\n",
    "        'targetencoder__min_samples_leaf': [1, 20]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = pipeline ,\n",
    "        param_grid = param_grid ,\n",
    "        cv = 3 ,                 \n",
    "        scoring = 'roc_auc' ,\n",
    "        n_jobs = -1 ,\n",
    "        verbose = 1\n",
    "    )\n",
    "\n",
    "    print(\"\\n\")\n",
    "    grid_search.fit(xc_train, yc_train)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 30)\n",
    "    print(f\"Best ROC_AUC: {grid_search.best_score_:.4f}\")\n",
    "    print(\"Best Parameters:\")\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    #تجربه فاشله لتحديد افضل المعاملات\n",
    "    #السبب انه عدد العينات كبير نسبيا ومدامني بجرب كل رقم بلوب لحال ف رح يوخذ مني وقت كبيييييير جدااااا\n",
    "    '''\n",
    "    smoothing_op = [1, 2, 10, 20, 50, 100]\n",
    "    leaf_op = [1, 5, 10, 20, 50]\n",
    "    Kfold_op = [3, 5, 10] \n",
    "\n",
    "    results = []\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for k in Kfold_op:\n",
    "        current_kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "        \n",
    "        for sm in smoothing_op:\n",
    "            for leaf in leaf_op:\n",
    "                \n",
    "                encoder = ce.TargetEncoder(\n",
    "                    cols=high_cols, \n",
    "                    min_samples_leaf=leaf, \n",
    "                    smoothing=sm\n",
    "                )\n",
    "                \n",
    "                model = LogisticRegression(solver='liblinear')\n",
    "                \n",
    "                pipeline = make_pipeline(encoder, model)\n",
    "                \n",
    "                try:\n",
    "                    scores = cross_val_score(pipeline, xc, yc, cv=current_kf, scoring=\"roc_auc\")\n",
    "                    mean_auc = scores.mean()\n",
    "                    std_auc = scores.std()\n",
    "                    \n",
    "                    results.append({\n",
    "                        'n_splits': k,\n",
    "                        'smoothing': sm,\n",
    "                        'min_samples_leaf': leaf,\n",
    "                        'auc_mean': mean_auc,\n",
    "                        'auc_std': std_auc\n",
    "                    })\n",
    "                    \n",
    "                    print(f\"K={k}, Smooth={sm}, Leaf={leaf} -> AUC: {mean_auc:.4f}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error at K={k}, Smooth={sm}, Leaf={leaf}: {e}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    sorted_results = results_df.sort_values(by='auc_mean', ascending=False)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"TOP 3 PARAMETER COMBINATIONS:\")\n",
    "    print(sorted_results.head(3))\n",
    "    print()\n",
    "\n",
    "    if not sorted_results.empty:\n",
    "        best_params = sorted_results.iloc[0]\n",
    "        print(f\"\\nthe best:\\nSmoothing: {best_params['smoothing']}\\nMin Samples Leaf: {best_params['min_samples_leaf']}\\nK-Fold Splits: {int(best_params['n_splits'])}\")\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def which_scaler(num_cols):\n",
    "\n",
    "    SAMPLE_SIZE = 500000 \n",
    "\n",
    "    if len(DF) > SAMPLE_SIZE:\n",
    "\n",
    "        df_sampled = DF.sample(n=SAMPLE_SIZE, random_state=42).copy()\n",
    "    else:\n",
    "        df_sampled = DF.copy()\n",
    "\n",
    "    fig, axes = plt.subplots(len(num_cols), 2, figsize=(14, 4 * len(num_cols)))\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "\n",
    "    for i, col in enumerate(num_cols):\n",
    "        \n",
    "        sns.histplot(\n",
    "            df_sampled[col], \n",
    "            kde=True, \n",
    "            ax=axes[i, 0], \n",
    "            color='skyblue', \n",
    "            edgecolor='black',\n",
    "            line_kws={'linewidth': 3}\n",
    "        )\n",
    "        axes[i, 0].set_title(f'Distribution of {col}', fontsize=12)\n",
    "        axes[i, 0].set_xlabel(col, fontsize=10)\n",
    "        axes[i, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "        stats.probplot(\n",
    "            df_sampled[col].dropna(), \n",
    "            dist=\"norm\", \n",
    "            plot=axes[i, 1]\n",
    "        )\n",
    "        axes[i, 1].set_title(f'Q-Q Plot of {col}', fontsize=12)\n",
    "        axes[i, 1].set_xlabel('Theoretical Quantiles (Normal)', fontsize=10)\n",
    "        axes[i, 1].set_ylabel('Sample Quantiles', fontsize=10)\n",
    "\n",
    "    plt.savefig('numerical_features_distribution_analysis.png', bbox_inches='tight')\n",
    "    print(\"تم حفظ تحليل التوزيعات في 'numerical_features_distribution_analysis.png'\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c1e124",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "num_cols = [\"order_hour_of_day\", \"days_since_prior_order\", \"add_to_cart_order\", \"order_number\"]\n",
    "low_cols = [\"department_id\", \"order_dow\"] \n",
    "high_cols = [\"user_id\", \"product_id\", \"aisle_id\"] \n",
    "target_col = \"reordered\"\n",
    "Frequency_col = \"product_name\"\n",
    "\n",
    "#الرسم ببينلك انه التوزيع مبعثر وغير طبيعي وبحتوي على اوتلايرز كثيييييررر ,  عشان هيك كان افضل خيار استخدام \n",
    "#SD لانه افضل بالتعامل مع الاوتلايرز وما بتأثر فيهم بشكل واضح وسلبي\n",
    "\n",
    "#which_scaler(num_cols)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1277eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"order_hour_of_day\", \"days_since_prior_order\", \"add_to_cart_order\", \"order_number\"]\n",
    "low_cols = [\"department_id\", \"order_dow\"] \n",
    "high_cols = [\"user_id\", \"product_id\", \"aisle_id\"] \n",
    "target_col = \"reordered\"\n",
    "Frequency_col = \"product_name\"\n",
    "\n",
    "KF = KFold(n_splits = 5 , shuffle = True , random_state = 42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"encoding\" , OneHotEncoder(handle_unknown = \"ignore\" , sparse_output = False , drop = \"first\") , low_cols) ,\n",
    "        (\"target_encoding\" , ce.TargetEncoder(min_samples_leaf = 20 , smoothing = 50) , high_cols) ,\n",
    "        (\"Frequency\" , ce.CountEncoder(normalize = True)) ,\n",
    "        (\"scaling\" , StandardScaler() , num_cols)\n",
    "                 ]\n",
    ")\n",
    "# معامل الفريكوانسي ترو ليش؟ , لانه اذا حطيتو فولز اللي رح يصير انه رح يوخذ عدد التكرارات زي ما هو في هيك بصير عندي تباين كبير ورح يصير بحاجه لسكيلينق \n",
    "#اما هيك اللي رح يعملو انه رح يحولهم لنسبة بين ال 0 وال 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deabb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#بعد اكثر من تجربه افضل ناتج طلعلي كن زي اللي حطيتهم بالبريبروسيس\n",
    "\n",
    "best_params_for_TE(DF , high_cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372fa85",
   "metadata": {},
   "source": [
    "6: feature engineering (mandatory list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bacd298",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_total_orders = Full_DataSet.groupby('user_id')\n",
    "user_total_orders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b414ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#total orders per user يعني كل مستخدم كم مره فات المحل واشترى يعني كم طلب عملو بشكل كامل مش كم منتج اشتراه بحياتو \n",
    "# طيب هون القروب باي بيجمعلي كل الداتا تبع كل يوزر ايدي لحال \n",
    "#بعدين بقله لكل يوزر بدي كولوم الاوردر نمبر تمام هسا الاورودر نمبر لكل زبون بمثل كل زبون كم طلب عملو لحد الان فا لو اخذتلو ال ماكس\n",
    "#لو اخذت الماكس رح تعطيني رقم اخر فاتوره والي بمثل عدد الطلبات الكلي لكل زبون طيب ممكن تسالني كان بمكاني اختار كاونت مش ماكس صح كلامك لكن\n",
    "#الداتا الي عندي او كولوم الاوردر نمبر يعني بحتوي على ارقام الطلبات مش عدد الطلبات فلو اخذت كاونت رح يطلعلي عدد المنتجات مش عدد الطلباتؤ\n",
    "#استخدمنا الريست اندكس عشان يرجعلي الداتا فريم مش سيرييز لانو قروب باي بيرجع سيرييز افتراضيا وبتخرب الداتا بصير اليوزر هو كولوم الاندكس\n",
    "user_total_orders = Full_DataSet.groupby('user_id')['order_number'].max().reset_index()\n",
    "# 3. بنسمي العمود اسم واضح عشان ما نتخربط بعدين\n",
    "user_total_orders.columns = ['user_id', 'user_total_orders']\n",
    "\n",
    "print(user_total_orders.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8efa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  average basket size\n",
    "#هذه الميزة بتحدد القدرة الشرائية Purchasing Power\n",
    "#وبتحدد نمط التسوق عند الزبون يعني بعرف الزبون الي عادته يشتري مثلا 50 غرض هاض زبون بمتوسط سلة كبيرة فا بهمني انو المودل ممكن \n",
    "#بهمني انو المودل ممكن يشوف هالشي ويستفيد منه بحيث لو كان شاري 3 اغراض بس يضل يقترح عليه لانو هالزبون من عادتو يشتري كثير \n",
    "\n",
    "#============================================================================================================\n",
    "\n",
    "#طيب السواال كيف بنحسبها ؟ بنحسبها عن طريق انو بنجيب لكل زبون كم المنتجات الي اشتراها بشكل كلي\n",
    "#بعدين بنجيب كم طلب عملو بشكل كلي\n",
    "#بعدين بنقسم المجموع على العدد\n",
    "#============================================================================================================\n",
    "#هون اولا عشان نجيب مجموع المنتجات الي اشتراها كل زبون بنجيب كولوم البروودكت ايدي وبنعمللو كاونت هيك بنعد كل المنتجات الي اشتراها\n",
    "#بعدين بنجيب كولوم الاوردر نمبر وبناخد الماكس زي ما شرحنا فوق عشان نعرف كم طلب عملو بشكل كلي\n",
    "\n",
    "#واستخدمنا ميثود الاقريقيت الي بتتيحلي اعمل اكشنز متعدده على كولمز مختلفه بنفس الوقت بدل ما اعمل قروب باي مرتين\n",
    "basket_data = Full_DataSet.groupby('user_id').agg({ 'product_id':'count', 'order_number': 'max'}).reset_index()\n",
    "\n",
    "# مجرد تسميت الكولمز بشكل واضح بس\n",
    "basket_data.columns = ['user_id', 'total_items_bought', 'total_orders_made']\n",
    "\n",
    "#الحسبه\n",
    "basket_data['avg_basket_size'] = basket_data['total_items_bought'] / basket_data['total_orders_made']\n",
    "\n",
    "print(basket_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a4785",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  User-Level Features full\n",
    "#هون لازم نعمل سورت اول عشان اخر مطلوب اللاست لاخر طلب فا ممكن يكون اخر طلب الي بجيبو مش هو اخر طلب عملو\n",
    "#بس الجهاز عندي بتحملش \n",
    "# Full_DataSet.sort_values(['user_id', 'order_number'], inplace=True)\n",
    "user_features = Full_DataSet.groupby('user_id').agg({\n",
    "      # 1. Total #Orders\n",
    "    'order_number': 'max',       \n",
    "    # 2. هاض بساعدنا نعرف كم منتج اشتراها كل زبون بشكل كلي\n",
    "     'product_id': 'count',       \n",
    "    # 3. Reorder Ratio\n",
    "    'reordered': 'mean',         \n",
    "\n",
    "   #هون حسبنا اخر مطلوبين بخطوه وحده بدل ما نعمل قروب باي مرتين\n",
    "    'days_since_prior_order': ['mean', 'last'] \n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "user_features.columns = ['user_id',  'user_total_orders',  'user_total_items', 'user_reorder_ratio','user_avg_days_between', 'user_days_since_last_order'  ]\n",
    "\n",
    "# Basket Size\n",
    "user_features['user_avg_basket_size'] = user_features['user_total_items'] / user_features['user_total_orders']\n",
    "\n",
    "#هاض العامود مش ضروري بعد ما حسبنا الافريج مابنحتاجه \n",
    "del user_features['user_total_items']\n",
    "\n",
    "display(user_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2c5a4",
   "metadata": {},
   "source": [
    "Product-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac0a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Product-Level Features ---\n",
    "\n",
    "# هالمره التجميع رح يكون حسب المنتج مش حسب اليوزر\n",
    "product_features = Full_DataSet.groupby('product_id').agg({\n",
    "    \n",
    "    #  Popularity \n",
    "    #هون شو ممكن يفيدنا هون قصدو من البوبولاريتي انه نعرف كم مرة انباع هاد المنتج ممكن من خلاله نعرف  اكثر المنتجات بينباع او وين اقل منتج\n",
    "    'user_id': 'count',  \n",
    "    # ليش user_id؟ وليش count؟\n",
    "    # عشان نعد كم زبون اشترى هاد المنتج لانو كل سطر بيمثل  عنا عمليه شراء.\n",
    "    #====================================================================================\n",
    "    #  Reorder Rate \n",
    "    #هون بنحسب نسبة اعادة الطلبات للمنتج\n",
    "    'reordered': 'mean', \n",
    "    #هاي واضحه من اسمها بدهاش اشي\n",
    "    #====================================================================================\n",
    "    # Average  Position\n",
    "    #طيب ممكن تسالني ليش اخترنا هاض الكولوم بالذات رح لانه بمثل ترتيب المنتج داخل السلة فلو اخذنا المين رح يعطينا ترتيب المنتج داخل السلة زي ماهو طالب\n",
    "    'add_to_cart_order': 'mean' \n",
    "   \n",
    "}).reset_index()\n",
    "\n",
    "product_features.columns = [ 'product_id', 'product_total_purchases', 'product_reorder_rate', 'product_avg_cart_position' ]\n",
    "\n",
    "display(product_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55efd949",
   "metadata": {},
   "source": [
    "User×Product interaction features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77231b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UserxProduct Interaction Features \n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "uxp_features = Full_DataSet.groupby(['user_id', 'product_id']).agg({\n",
    "# Total Purchases of Product by User\n",
    "#هون عشان نجيبها كان ممكن نستخدم اي عمود بس بدنا واحد  بس المهم نعد كم مرة هاد الزبون اشترا هاد المنتج \n",
    "#طب ليش اخترت هاض الكولوم بالذات اختصارا للوقت بس عشان المطلوب الثاني رح ارجع اطلبه تمام\n",
    "#====================================================================================\n",
    "    \n",
    "# Reorder Probability of Product by User\n",
    "#هون استخدمنا برضو بنفس العامود بس اخذنا المين عشان يعطينا النسبة الي طلبها الزبون من هاد المنتج\n",
    "    'reordered': ['count', 'mean'], \n",
    "    \n",
    "    'days_since_prior_order': 'max'    # هاي مش عارف اعملها علقت كيف ممكن نجيب ال   days since last purchase by       \n",
    "}).reset_index()\n",
    "\n",
    "# 2. تسمية الأعمدة بشكل واضح (عشان الدكتور يفهم كل عمود شو هو)\n",
    "uxp_features.columns = [\n",
    "    'user_id', \n",
    "    'product_id', \n",
    "    'uxp_total_bought',       \n",
    "    'uxp_reorder_ratio',      \n",
    "    'uxp_days_last_order_'     \n",
    "]\n",
    "\n",
    "display(uxp_features.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc48c8af",
   "metadata": {},
   "source": [
    "Temporal features: hour/day/month/year, season, holiday flags (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796fe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# طيب هون المطلوب منا بالتيمبورال فيشترز انو نزبط الوقت مثلا نخليه صبح ومسا ومثلا الايام نقسمها ايام عاديه وايام عطله والشهر \n",
    "#بس مبادايا الشهر والسنه والموسم مابنقدر لانو مامعنا معلومات عنها  في رح نكتفي بالساعات واليوم \n",
    "#نبدا بالساعات هسا التوقيت  عنا من 0 ل 23 فممكن نقسمهم لثلاث فترات\n",
    "def time_of_day(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return 'Morning'\n",
    "    elif 12 <= hour < 17:\n",
    "        return 'Afternoon'\n",
    "    elif 17 <= hour < 21:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Midnight'\n",
    "Full_DataSet['time_of_day'] = Full_DataSet['order_hour_of_day'].apply(time_of_day)\n",
    "print(Full_DataSet['time_of_day'].head(10))\n",
    "print(\"==\"*40)\n",
    "#طيب قلنا للايام بنقسمها لايام عاديه وايام عطله\n",
    "#وزي مابنعرف بالداتا الي عندي السبت والاحد همه العطله فرقمهم بكون 0 و 1 \n",
    "#هون اختصارا على حالنا لقدام خليت الكولوم الجديد عباره عن ارقام 0 و 1 بدل ما اخليها نصوص عشان اسهل التعامل معها بعدين   \n",
    "def day_type(day):\n",
    "    if (day == 0) or (day == 1):\n",
    "        return 1 # طبعا واحد بتعني انها شسمو ويكند\n",
    "    else:\n",
    "        return 0\n",
    "Full_DataSet['is_weekend'] = Full_DataSet['order_dow'].apply(day_type)\n",
    "print(Full_DataSet['is_weekend'].head(30))\n",
    "#حطيت 30 لانو خفت كلها صفار ههههه يسعد ربك \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d0e9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Aggregations over Windows (Last 3 Orders) - بدون Lambda ---\n",
    "\n",
    "# 1. تجهيز الداتا: بنحسب حجم السلة لكل طلب (جدول صغير وخفيف)\n",
    "orders_summary = Full_DataSet.groupby(['user_id', 'order_number']).size().reset_index(name='basket_size')\n",
    "\n",
    "# 2. الترتيب (مهم جداً): عشان لما نقول \"آخر 3\" يكونوا عنجد آخر 3 زمنياً\n",
    "orders_summary = orders_summary.sort_values(['user_id', 'order_number'])\n",
    "\n",
    "# 3. تعريف الفنكشن العادي (بدل اللمدا)\n",
    "# هذا الفنكشن بياخذ عمود أرقام، وبحسب المتوسط المتحرك لآخر 3 قيم\n",
    "def calculate_last_3_avg(series):\n",
    "    # window=3: يعني خذ 3 قيم\n",
    "    # min_periods=1: يعني حتى لو الزبون عنده طلب واحد بس، احسبله المعدل (ما ترجع Null)\n",
    "    return series.rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "# 4. تطبيق الفنكشن على كل زبون\n",
    "# transform: بتمسك الفنكشن اللي كتبناه فوق، وبتطبقه على كل \"مجموعة\" (زبون)\n",
    "orders_summary['rolling_avg_3_orders'] = orders_summary.groupby('user_id')['basket_size'].transform(calculate_last_3_avg)\n",
    "\n",
    "# 5. النتيجة النهائية\n",
    "# احنا بهمنا \"آخر وضع\" وصله الزبون، فبناخذ آخر سطر لكل زبون\n",
    "user_window_features = orders_summary.groupby('user_id').last().reset_index()\n",
    "\n",
    "# ترتيب وتنظيف الجدول النهائي\n",
    "user_window_features = user_window_features[['user_id', 'rolling_avg_3_orders']]\n",
    "user_window_features.columns = ['user_id', 'u_avg_basket_last_3']\n",
    "\n",
    "display(user_window_features.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba4a0f9",
   "metadata": {},
   "source": [
    "✅ تم حساب (Rolling Window) باستخدام فنكشن عادي!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff55361",
   "metadata": {},
   "source": [
    "At least one engineered non-linear feature : log transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fff0338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# افترض إنك حسبت user_features في الخطوة الأولى\n",
    "# بدنا نحول عمود \"عدد الطلبات\" باستخدام اللوغاريتم\n",
    "#هسا\n",
    "print(\"=\")\n",
    "#هون طقعت ديسبلاي لانها اوضح بس من برنت \n",
    "user_features['u_total_orders_log'] = np.log(user_features['user_total_orders'])\n",
    "\n",
    "# حطيناهم جمب بعض عشان تشوف الفرق \n",
    "print(\"user_total_orders trasform\")\n",
    "display(user_features[['user_total_orders', 'u_total_orders_log']].head(90))\n",
    "#\n",
    "#كمان فيتشر ثاني نعملو مش غلط \n",
    "product_features['p_total_purchases_log'] = np.log(product_features['product_total_purchases'])\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"product_ total_purchases transform\")\n",
    "# use the correct column name that was created above\n",
    "display(product_features[['product_total_purchases', 'p_total_purchases_log']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fa79c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f347b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac7c25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4c2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da99f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
