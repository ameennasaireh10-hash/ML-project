{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Kaggle_Final_Project",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7487,
          "sourceType": "datasetVersion",
          "datasetId": 4931
        }
      ],
      "dockerImageVersionId": 31234,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ameennasaireh10-hash/ML-project/blob/main/Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "psparks_instacart_market_basket_analysis_path = kagglehub.dataset_download('psparks/instacart-market-basket-analysis')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "Ow-oEU3l9Rkw"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "0: reading the data"
      ],
      "metadata": {
        "id": "29378f98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders\n",
        "!pip install mglearn\n",
        "!pip install statsmodels"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:55:16.739762Z",
          "iopub.execute_input": "2025-12-26T11:55:16.74084Z",
          "iopub.status.idle": "2025-12-26T11:55:29.607277Z",
          "shell.execute_reply.started": "2025-12-26T11:55:16.740805Z",
          "shell.execute_reply": "2025-12-26T11:55:29.606066Z"
        },
        "id": "c3d9fd11-0cfd-4ff1-b769-d46a70406fba"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# بنحدث المكتبتين مع بعض عشان نضمن التوافق\n",
        "!pip install --upgrade scikit-learn imbalanced-learn"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:55:29.609068Z",
          "iopub.execute_input": "2025-12-26T11:55:29.609381Z",
          "iopub.status.idle": "2025-12-26T11:55:39.057903Z",
          "shell.execute_reply.started": "2025-12-26T11:55:29.60935Z",
          "shell.execute_reply": "2025-12-26T11:55:39.057Z"
        },
        "id": "8d57a117-814c-4853-b3c3-797530959927"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. أول شي بننظف النسخ اللي عملت مشاكل\n",
        "!pip uninstall scikit-learn imbalanced-learn -y\n",
        "\n",
        "# 2. بننزل النسخة \"الذهبية\" (1.5.2) اللي بترضي كل الأطراف\n",
        "!pip install scikit-learn==1.5.2 imbalanced-learn==0.12.3 category-encoders==2.6.3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:55:39.059425Z",
          "iopub.execute_input": "2025-12-26T11:55:39.059808Z",
          "iopub.status.idle": "2025-12-26T11:55:47.919333Z",
          "shell.execute_reply.started": "2025-12-26T11:55:39.059765Z",
          "shell.execute_reply": "2025-12-26T11:55:47.918291Z"
        },
        "id": "8358b76b-4ba2-4bfb-bdf7-0f9a60e104e8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import mglearn as mg\n",
        "import gc\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline , make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder , StandardScaler , LabelEncoder , OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.neighbors import KNeighborsClassifier , KNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split , KFold , cross_val_score , GridSearchCV , TimeSeriesSplit, GroupKFold\n",
        "from sklearn.linear_model import Lasso , LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error , mean_squared_error, r2_score\n",
        "import seaborn as sb\n",
        "import category_encoders as ce\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.tree import DecisionTreeRegressor , DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "6b9ac008",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:53:18.932863Z",
          "iopub.execute_input": "2025-12-26T12:53:18.933261Z",
          "iopub.status.idle": "2025-12-26T12:53:18.940725Z",
          "shell.execute_reply.started": "2025-12-26T12:53:18.93323Z",
          "shell.execute_reply": "2025-12-26T12:53:18.939926Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# aisles = pd.read_csv(r\"archive\\aisles.csv\")\n",
        "# department = pd.read_csv(r\"archive\\departments.csv\")\n",
        "# pro_prior = pd.read_csv(r\"archive\\order_products__prior.csv\")\n",
        "# pro_train = pd.read_csv(r\"archive/order_products__train.csv\")\n",
        "# orders = pd.read_csv(r\"archive\\orders.csv\")\n",
        "# products = pd.read_csv(r\"archive\\products.csv\")\n",
        "aisles = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/aisles.csv\")\n",
        "department = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/departments.csv\")\n",
        "pro_prior = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/order_products__prior.csv\")\n",
        "pro_train = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/order_products__train.csv\")\n",
        "orders = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/orders.csv\")\n",
        "products = pd.read_csv(r\"/kaggle/input/instacart-market-basket-analysis/products.csv\")"
      ],
      "metadata": {
        "id": "2a6535d9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:55:50.441948Z",
          "iopub.execute_input": "2025-12-26T11:55:50.442391Z",
          "iopub.status.idle": "2025-12-26T11:56:07.911197Z",
          "shell.execute_reply.started": "2025-12-26T11:55:50.442364Z",
          "shell.execute_reply": "2025-12-26T11:56:07.910379Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: Joins and memory optimization"
      ],
      "metadata": {
        "id": "dbb53e77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# دالة تقليل الحجم المحسنة (بتختار النوع المناسب بدقة)\n",
        "def reduce_memory(df):\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        if col_type != object:\n",
        "            # Prevent conversion of ID columns to float16, they should be int\n",
        "            if col in ['order_id', 'product_id', 'user_id', 'aisle_id', 'department_id']:\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    df[col] = df[col].astype(np.int32) # Keep them as int32 or appropriate int type\n",
        "                else: # If they are already float but represent IDs, convert to int then int32\n",
        "                    df[col] = df[col].fillna(-1).astype(np.int32) # Fill NaN with a placeholder before converting to int\n",
        "                continue # Skip further processing for these columns\n",
        "\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "            else:\n",
        "                # Avoid float16 for columns that might be used as merge keys or indices\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64) # Use float64 as a safe default if not fitting float32\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "    return df"
      ],
      "metadata": {
        "id": "8b03abb2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:07.91252Z",
          "iopub.execute_input": "2025-12-26T11:56:07.913198Z",
          "iopub.status.idle": "2025-12-26T11:56:07.922586Z",
          "shell.execute_reply.started": "2025-12-26T11:56:07.913135Z",
          "shell.execute_reply": "2025-12-26T11:56:07.92179Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = [aisles , department , pro_prior , pro_train , orders , products]\n",
        "\n",
        "for i in range(len(dfs)):\n",
        "    dfs[i] = reduce_memory(dfs[i])"
      ],
      "metadata": {
        "id": "7c8d6cd4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:07.923694Z",
          "iopub.execute_input": "2025-12-26T11:56:07.92408Z",
          "iopub.status.idle": "2025-12-26T11:56:08.827107Z",
          "shell.execute_reply.started": "2025-12-26T11:56:07.924041Z",
          "shell.execute_reply": "2025-12-26T11:56:08.826199Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#   في m1\n",
        "#   pro_prior بلشنا ب هذول لانه يحتوي تفاصيل المنتجات داخل الطلبات\n",
        "#   orders هو اللي بحتوي على معلومات الطلب , المستخدم , الوقت\n",
        "# #   في m1\n",
        "# #   pro_prior بلشنا ب هذول لانه يحتوي تفاصيل المنتجات داخل الطلبات\n",
        "# #   orders هو اللي بحتوي على معلومات الطلب , المستخدم , الوقت\n",
        "# m1 = pd.merge(pro_prior , orders , on = \"order_id\" , how = \"left\")\n",
        "# m2 = pd.merge(m1 , products , on = \"product_id\" , how = \"left\")\n",
        "# m3 = pd.merge(m2 , department , on = \"department_id\" , how = \"left\")\n",
        "# Full_DataSet = pd.merge(m3 , aisles , on = \"aisle_id\" , how = \"left\")\n",
        "print(\"Merging process started...\")\n",
        "\n",
        "# 1. دمج Prior مع Orders\n",
        "Full_DataSet = pd.merge(pro_prior, orders, on=\"order_id\", how=\"left\")\n",
        "# حذف القديم فوراً\n",
        "del pro_prior, orders\n",
        "gc.collect()\n",
        "\n",
        "# 2. دمج Products\n",
        "Full_DataSet = pd.merge(Full_DataSet, products, on=\"product_id\", how=\"left\")\n",
        "del products\n",
        "gc.collect()\n",
        "\n",
        "# 3. دمج Departments & Aisles\n",
        "Full_DataSet = pd.merge(Full_DataSet, department, on=\"department_id\", how=\"left\")\n",
        "Full_DataSet = pd.merge(Full_DataSet, aisles, on=\"aisle_id\", how=\"left\")\n",
        "# del department, aisles\n",
        "gc.collect()\n",
        "\n",
        "# حذف الأعمدة غير المهمة\n",
        "# del Full_DataSet[\"eval_set\"]\n",
        "# لو بدك تحذف department نصي وتخلي الـ id\n",
        "# if 'department' in Full_DataSet.columns: del Full_DataSet[\"department\"]\n",
        "# if 'aisle' in Full_DataSet.columns: del Full_DataSet[\"aisle\"]\n",
        "\n",
        "gc.collect()\n",
        "print(\"Merge Done & RAM Cleaned! ✅\")"
      ],
      "metadata": {
        "id": "542d99fa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:08.828242Z",
          "iopub.execute_input": "2025-12-26T11:56:08.828511Z",
          "iopub.status.idle": "2025-12-26T11:56:24.23444Z",
          "shell.execute_reply.started": "2025-12-26T11:56:08.828488Z",
          "shell.execute_reply": "2025-12-26T11:56:24.233433Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(Full_DataSet.info())"
      ],
      "metadata": {
        "id": "f3c2a575",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:24.235612Z",
          "iopub.execute_input": "2025-12-26T11:56:24.235939Z",
          "iopub.status.idle": "2025-12-26T11:56:24.292075Z",
          "shell.execute_reply.started": "2025-12-26T11:56:24.235901Z",
          "shell.execute_reply": "2025-12-26T11:56:24.291122Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#كنت بدي اصير اعمل قراءه للملف مره ثانيه عشان ما اضل اعمل دمج كل ما اشغل الكود , بس اكتشفت انه تحميله بقعد وقت اكثر\n",
        "#Full_DataSet.to_csv('archive/full_instacart_data.csv', index=False)"
      ],
      "metadata": {
        "id": "08db0c66",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:24.295071Z",
          "iopub.execute_input": "2025-12-26T11:56:24.295367Z",
          "iopub.status.idle": "2025-12-26T11:56:24.299103Z",
          "shell.execute_reply.started": "2025-12-26T11:56:24.295341Z",
          "shell.execute_reply": "2025-12-26T11:56:24.298127Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "2: EDA"
      ],
      "metadata": {
        "id": "e07c4665"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cheking for null values\n",
        "missing_values = Full_DataSet.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "print( missing_values )\n",
        "print(\"==\"*40 )\n",
        "missing_percent = (missing_values / len(Full_DataSet)) * 100\n",
        "print(f\"Percentage of missing values in columns\\n {missing_percent}\", )\n",
        "\n",
        "missing_percent.plot(kind='bar', figsize=(8, 5), width=0.3, color='red', rot=0)\n",
        "plt.ylabel(\"Missing Percentage\")\n",
        "plt.title(\"Missing Values Percentage per Feature\")\n",
        "plt.show()\n",
        "# هاي مش قيم مفقوده بالغلط هاي بتدل انه الزبون اول مره بيطلب فمفيش عندو قيمه ل days_since_prior_order"
      ],
      "metadata": {
        "id": "ae9e07c3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:24.300539Z",
          "iopub.execute_input": "2025-12-26T11:56:24.300876Z",
          "iopub.status.idle": "2025-12-26T11:56:25.0131Z",
          "shell.execute_reply.started": "2025-12-26T11:56:24.300843Z",
          "shell.execute_reply": "2025-12-26T11:56:25.012267Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution plots for numeric features and target(s) (histogram, density).\n"
      ],
      "metadata": {
        "id": "b1fbfa82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# لازم نختار الاعمده الرقميه الي الها معنى او بتفيدنا لو عملنا الها هستوغرام او دينستي بالاحرى مين مهم افهم الديستربويشن تبعو\n",
        "Full_DataSet['order_hour_of_day'].plot(kind='hist', bins=24, figsize=(10, 6), title='Distribution of Orders by Hour of Day')\n",
        "\n",
        "#Histogram (المدرج التكراري) رسمة أعمدة بتبين الكمية في كل فترة\n",
        "\n",
        "plt.xlabel('Hour of Day (0 - 23)') # سمينا المحور عشان الدكتور يفهم\n",
        "\n",
        "plt.ylabel('Frequency (Number of Orders)')\n",
        "plt.show()\n",
        "\n",
        "#بنلاحظ  فوق الوقت الي بكون فيه وقت الذروه للزباين متى بكون باليوم"
      ],
      "metadata": {
        "id": "f0a2dd7a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:25.01425Z",
          "iopub.execute_input": "2025-12-26T11:56:25.014594Z",
          "iopub.status.idle": "2025-12-26T11:56:26.334202Z",
          "shell.execute_reply.started": "2025-12-26T11:56:25.01456Z",
          "shell.execute_reply": "2025-12-26T11:56:26.333219Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Full_DataSet['days_since_prior_order'].plot(kind='hist', bins=30, figsize=(7, 6), color='orange', title='Distribution of Days Since Prior Order')\n",
        "\n",
        "plt.xlabel('Days Since Last Order')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4e9dc89c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:26.335319Z",
          "iopub.execute_input": "2025-12-26T11:56:26.335559Z",
          "iopub.status.idle": "2025-12-26T11:56:27.431546Z",
          "shell.execute_reply.started": "2025-12-26T11:56:26.335537Z",
          "shell.execute_reply": "2025-12-26T11:56:27.430672Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Weekly shoppers (peak at 7 days) and Monthly shoppers (peak at 30 days). The spike at 30 days also includes customers who haven't ordered for more than a month"
      ],
      "metadata": {
        "id": "f6b1c24a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:27.432528Z",
          "iopub.execute_input": "2025-12-26T11:56:27.432852Z",
          "iopub.status.idle": "2025-12-26T11:56:27.436754Z",
          "shell.execute_reply.started": "2025-12-26T11:56:27.43281Z",
          "shell.execute_reply": "2025-12-26T11:56:27.436026Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''# 1. نأخذ عينة عشوائية (10% مثلاً) عشان الرام ما تنفجر\n",
        "# هذا العمود يمثل \"ساعات اليوم\" من 0 لـ 23\n",
        "sample_hours = Full_DataSet['order_hour_of_day'].sample(frac=0.1, random_state=42)\n",
        "\n",
        "# 2. الرسم\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "sample_hours.plot(kind='kde', color='green', title='Density Plot of Order Hour of Day')\n",
        "\n",
        "plt.xlabel('Hour of Day (0-23)')\n",
        "plt.xlim(0, 23) # عشان نحصر الرسمة في حدود اليوم\n",
        "plt.show()\n",
        "\n",
        "#الدينستي بعطينا هون تفاصيل اكثر او معبر اكثر بس بوخذ وقت اكثر للامانه '''\n"
      ],
      "metadata": {
        "id": "91573d7f",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:27.437674Z",
          "iopub.execute_input": "2025-12-26T11:56:27.438293Z",
          "iopub.status.idle": "2025-12-26T11:56:27.453877Z",
          "shell.execute_reply.started": "2025-12-26T11:56:27.438264Z",
          "shell.execute_reply": "2025-12-26T11:56:27.45326Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Categorical cardinality analysis (barplots / top-k frequencies)."
      ],
      "metadata": {
        "id": "9815cbf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first we need to do some cardinality checking for the catorgorical features\n",
        "categorical_cols = Full_DataSet.select_dtypes(include=['category']).columns\n",
        "categorical_cols\n",
        "\n"
      ],
      "metadata": {
        "id": "3c21bba9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:27.455127Z",
          "iopub.execute_input": "2025-12-26T11:56:27.455506Z",
          "iopub.status.idle": "2025-12-26T11:56:27.560323Z",
          "shell.execute_reply.started": "2025-12-26T11:56:27.455469Z",
          "shell.execute_reply": "2025-12-26T11:56:27.559373Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Full_DataSet[\"product_name\"].value_counts() # هون بنلاحظ انو في منتجات كتير متكرره يعني الكارديناليتي عاليه فهاض العامود مابفيدني اعملو فيجواليزشن"
      ],
      "metadata": {
        "id": "4983a57e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:27.561323Z",
          "iopub.execute_input": "2025-12-26T11:56:27.561565Z",
          "iopub.status.idle": "2025-12-26T11:56:27.778643Z",
          "shell.execute_reply.started": "2025-12-26T11:56:27.561543Z",
          "shell.execute_reply": "2025-12-26T11:56:27.777686Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# نعمل فحص للباقي\n",
        "checking = ['department', 'aisle', 'product_name']\n",
        "\n",
        "cardinality_counts = Full_DataSet[checking].nunique()\n",
        "print(\"عدد الأنواع في كل عمود\")\n",
        "print(cardinality_counts)\n",
        "# هون بنلاحظ الديبراتمنت فيه تنوع واطي فا بنقدر نعملو فيجواليز ونستفيد منه\n",
        "# الممرات 134 يعتبر عاللي فامبنقدر نرسمو كلو رح نوخذ الاكثر تكرارا تمام نفس الحاله بنطبقها على اسماء المنتجات"
      ],
      "metadata": {
        "id": "09a96f72",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:27.780022Z",
          "iopub.execute_input": "2025-12-26T11:56:27.780409Z",
          "iopub.status.idle": "2025-12-26T11:56:28.39397Z",
          "shell.execute_reply.started": "2025-12-26T11:56:27.780381Z",
          "shell.execute_reply": "2025-12-26T11:56:28.393234Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# what is eval_set refer to ?\n",
        "Full_DataSet['eval_set'].value_counts()\n",
        "# هون شفنا انو هاض العامود بحتوي على داتا بتمثل الطلبات القديمه فهاض الاشي مابفيدني اني اعملو فيجواليز"
      ],
      "metadata": {
        "id": "e9bbad05",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:28.395035Z",
          "iopub.execute_input": "2025-12-26T11:56:28.395313Z",
          "iopub.status.idle": "2025-12-26T11:56:28.581564Z",
          "shell.execute_reply.started": "2025-12-26T11:56:28.395288Z",
          "shell.execute_reply": "2025-12-26T11:56:28.580692Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#  بنرسمه كأعمدة Barplot\n",
        "Full_DataSet['department'].value_counts().plot(kind='bar', figsize=(12,6) , color='blue')\n",
        "\n",
        "plt.title('Total Orders per Department', fontsize=15)\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xlabel('Department Name')\n",
        "plt.xticks(rotation=45, ha='right') # ميلنا الأسماء عشان نقرأها بوضوح\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "17ab5451",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:28.582619Z",
          "iopub.execute_input": "2025-12-26T11:56:28.582872Z",
          "iopub.status.idle": "2025-12-26T11:56:28.960226Z",
          "shell.execute_reply.started": "2025-12-26T11:56:28.582849Z",
          "shell.execute_reply": "2025-12-26T11:56:28.959259Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "top_aisles = Full_DataSet['aisle'].value_counts().head(25)\n",
        "#  هون ممكن تسالني انت طيب كيف رتبتهم من الاكثر للاقل ؟ لان الميثود تاعت الفاليوز بالديفولت تاعها بترتبهم من الاكبر لاصغبر\n",
        "\n",
        "top_aisles.plot(kind='bar',figsize=(12, 6), color='blue')\n",
        "\n",
        "\n",
        "plt.title('Top 25 Best Selling aisles ', fontsize=14)\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xlabel('Aisle Name')\n",
        "plt.xticks(rotation=45, ha='right') # ميلنا الكلام بزاوية 45 عشان ينقرأ بوضوح\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2670448a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:28.961522Z",
          "iopub.execute_input": "2025-12-26T11:56:28.962049Z",
          "iopub.status.idle": "2025-12-26T11:56:29.376634Z",
          "shell.execute_reply.started": "2025-12-26T11:56:28.962013Z",
          "shell.execute_reply": "2025-12-26T11:56:29.375815Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "products_for_visuals = Full_DataSet['product_name'].value_counts().head(20) # هون اخذنا اكثر 20 بس عشان يصير مقروء بشكل احسن\n",
        "\n",
        "products_for_visuals.plot(kind='bar', figsize=(12, 6), color='blue')\n",
        "plt.title('Top 25 Best Selling Products ', fontsize=14)\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xlabel('Product Name')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ccf6739",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:29.377856Z",
          "iopub.execute_input": "2025-12-26T11:56:29.378201Z",
          "iopub.status.idle": "2025-12-26T11:56:29.79374Z",
          "shell.execute_reply.started": "2025-12-26T11:56:29.378139Z",
          "shell.execute_reply": "2025-12-26T11:56:29.792842Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Correlation matrix, heatmap and pairwise scatter plots for selected numeric features."
      ],
      "metadata": {
        "id": "c677155a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  هاي الخطوة بدنا نعرف شو العوامل اللي بتخلي الزبون يعمل اعادة طلب او reorder\n",
        "# في هاي الحاله لازم نختار الاعمده الرقميه الي الها سلوك او بمعنى اصح الها معنى"
      ],
      "metadata": {
        "id": "67ff9079",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:29.794763Z",
          "iopub.execute_input": "2025-12-26T11:56:29.795039Z",
          "iopub.status.idle": "2025-12-26T11:56:29.798995Z",
          "shell.execute_reply.started": "2025-12-26T11:56:29.795013Z",
          "shell.execute_reply": "2025-12-26T11:56:29.798146Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = [\n",
        "    'order_number',\n",
        "    'order_dow',\n",
        "    'order_hour_of_day',\n",
        "    'days_since_prior_order',\n",
        "    'add_to_cart_order',\n",
        "    'reordered' # هاض العامود الي بدنا نعرف شو العوامل الي بتأثر عليه مثل ماقلنا فوق\n",
        "]\n",
        "\n",
        "# 2. حساب المصفوفة (Correlation Matrix)\n",
        "# الدالة .corr() هي العقل المدبر اللي بيحسب العلاقات\n",
        "corr_matrix = Full_DataSet[selected_features].corr()\n",
        "\n",
        "\n",
        "# annot=True: عشان يكتب الرقم جوا المربع\n",
        "# cmap='coolwarm': ألوان (أحمر للحار/الموجب، أزرق للبارد/السالب)\n",
        "# fmt='.2f': منزلتين عشريتين بس\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5, square=False)\n",
        "\n",
        "plt.title('Correlation Heatmap of Numeric Features', fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "e009d53e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:29.800817Z",
          "iopub.execute_input": "2025-12-26T11:56:29.801078Z",
          "iopub.status.idle": "2025-12-26T11:56:34.633799Z",
          "shell.execute_reply.started": "2025-12-26T11:56:29.801055Z",
          "shell.execute_reply": "2025-12-26T11:56:34.632896Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. نأخذ عينة صغيرة جداً (1000 سطر) عشان الرسم يكون خفيف وواضح\n",
        "# Scatter Plot بيموت لو الداتا كبيرة\n",
        "scatter_sample = Full_DataSet.sample(n=1000, random_state=42)\n",
        "\n",
        "# 2. تحديد الأعمدة اللي بدنا نشوف علاقتها ببعض\n",
        "# ركزنا على أهم 3 أعمدة عشان ما نضيع وقت\n",
        "cols_to_plot = ['add_to_cart_order', 'days_since_prior_order', 'reordered']\n",
        "\n",
        "# 3. رسم الـ Pairplot\n",
        "# hue='reordered': عشان يلون النقاط (برتقالي للمكرر، أزرق للجديد)\n",
        "sns.pairplot(scatter_sample[cols_to_plot], hue='reordered', palette='husl', height=3)\n",
        "\n",
        "plt.suptitle('Pairwise Scatter Plots ', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "447b5667",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:34.635128Z",
          "iopub.execute_input": "2025-12-26T11:56:34.635525Z",
          "iopub.status.idle": "2025-12-26T11:56:37.152441Z",
          "shell.execute_reply.started": "2025-12-26T11:56:34.635486Z",
          "shell.execute_reply": "2025-12-26T11:56:37.151456Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#طيب اللون الاخضر هون بمثل المنتجات المعاد شرائها بنلاحظ بالرسمه انو دايما بالبدايه ببدا الزبون يجيب اغراضو الي  متعود عليها\n",
        "#بعدين بعد ما يجيبهم بجيب او بجرب اغراض جديده  مثل مابثمل اللون الزهري الي بمثل الاشياء الجديده\n",
        "#الرسمة الشمال تحت النقط بتوريك إن المنتجات المكررة الخضراء دايما محجوز الها المقاعد الأولى بالسلة  بغض النظر عن كم يوم مر.\n",
        "\n",
        "# الرسمة اليمين جبال بتأكد إن الناس بتتسوق بنظام أسبوعي أو شهري والمنتجات الجديدة والقديمة بتمشي على نفس هذا النظام."
      ],
      "metadata": {
        "id": "70efd15a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:37.153643Z",
          "iopub.execute_input": "2025-12-26T11:56:37.154Z",
          "iopub.status.idle": "2025-12-26T11:56:37.158194Z",
          "shell.execute_reply.started": "2025-12-26T11:56:37.153963Z",
          "shell.execute_reply": "2025-12-26T11:56:37.157422Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "• Time-of-day, day-of-week, and monthly seasonality plots"
      ],
      "metadata": {
        "id": "cbcb4df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hourrr=Full_DataSet['order_hour_of_day'].value_counts()\n",
        "hourrr"
      ],
      "metadata": {
        "id": "2cb1c68a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:37.159151Z",
          "iopub.execute_input": "2025-12-26T11:56:37.15953Z",
          "iopub.status.idle": "2025-12-26T11:56:37.34705Z",
          "shell.execute_reply.started": "2025-12-26T11:56:37.159495Z",
          "shell.execute_reply": "2025-12-26T11:56:37.346246Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(16, 7))\n",
        "\n",
        "\n",
        "# هون لازم قبل مانرسم نجهز الداتا لانها عباره عن مليون سطر فا لازم نرتبها اول حسب التكرار بعدين بنرتبها حسب الاندكس تصاعدني\n",
        "hour_counts = Full_DataSet['order_hour_of_day'].value_counts().sort_index()\n",
        "#لو تركناها هيك لاحظت رح تطلع معنا الرسمه الساعات من صفر ل 23 فا حيكون شوي مش مقروء الوضع فا افترحت لو بدنا نوري هالرسمه لاي حد لو نزبط الاندكس\n",
        "#ونخليه بنظام am و pm\n",
        "#بكون احسن ليش فقط عشان نخليه مقروء واريح للعين اكثر\n",
        "labels_of_hours = [\n",
        "    \"12 AM\", \"1 AM\", \"2 AM\", \"3 AM\", \"4 AM\", \"5 AM\",\n",
        "    \"6 AM\", \"7 AM\", \"8 AM\", \"9 AM\", \"10 AM\", \"11 AM\",\n",
        "    \"12 PM\", \"1 PM\", \"2 PM\", \"3 PM\", \"4 PM\", \"5 PM\",\n",
        "    \"6 PM\", \"7 PM\", \"8 PM\", \"9 PM\", \"10 PM\", \"11 PM\"\n",
        "]\n",
        "# x=labels_of_hours (الساعات)\n",
        "# y=hour_counts.values (عدد الطلبات)\n",
        "#هون اخترنا بار بلوت عشان سريع وبرضو برسملنا ال 24 عمود بسرعه عاليه\n",
        "sns.barplot(x=labels_of_hours, y=hour_counts.values, color='orange',)\n",
        "\n",
        "plt.title('Time of day Orders', fontsize=15)\n",
        "plt.xlabel('Hours: 12 AM - 11 PM  ', fontsize=12,color='blue')\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aff76183",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:37.35426Z",
          "iopub.execute_input": "2025-12-26T11:56:37.354616Z",
          "iopub.status.idle": "2025-12-26T11:56:37.797728Z",
          "shell.execute_reply.started": "2025-12-26T11:56:37.354576Z",
          "shell.execute_reply": "2025-12-26T11:56:37.796749Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# رح يطلع معنا 7 أرقام من 0 ـ 6\n",
        "day_counts = Full_DataSet['order_dow'].value_counts().sort_index()\n",
        "\n",
        "#بنرتبهم كمان مره زي ماعملنا فوق\n",
        " # الويك إند عند الاجانب ببدا من السبت فهو رح يكون رقم صفر\n",
        "days_labels = [\"Saturday\",  \"Sunday\", \"Monday\",  \"Tuesday\", \"Wednesday\", \"Thursday\",\"Friday \"]\n",
        "\n",
        "\n",
        "\n",
        "sns.barplot(x=days_labels, y=day_counts.values, color=\"orange\")\n",
        "\n",
        "plt.title('Orders Day of Week ', fontsize=15)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xlabel('Day', fontsize=12)\n",
        "\n",
        "plt.show()\n",
        "#بنلاحظ انو بالويكند اعلى طلبات وهاض المنطقي لانو الناس بتكون معطله"
      ],
      "metadata": {
        "id": "684a6487",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:37.798867Z",
          "iopub.execute_input": "2025-12-26T11:56:37.799544Z",
          "iopub.status.idle": "2025-12-26T11:56:38.280928Z",
          "shell.execute_reply.started": "2025-12-26T11:56:37.799515Z",
          "shell.execute_reply": "2025-12-26T11:56:38.279988Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "#  هون رح نستخدم هاض الكولوم لانو انسب اشي للمنثلي لانو مافي عنا بالداتا سيت كولم عن الاشهر\n",
        "days_of_month_counts = Full_DataSet['days_since_prior_order'].value_counts().sort_index()\n",
        "#رح نستخدم اللاين بلوت عشان نوضح التغيرات بشكل افضل\n",
        "sns.lineplot(x=days_of_month_counts.index, y=days_of_month_counts.values, marker='o', color='red', linewidth=2)\n",
        "\n",
        "# 3. تحسين المحاور\n",
        "plt.title('Monthly Seasonality', fontsize=14)\n",
        "plt.xlabel('Days Since Last Order', fontsize=12)\n",
        "plt.ylabel('Number of Orders', fontsize=12)\n",
        "plt.show()\n",
        "#بنلاحظ في قمه عند ال 7 و 30 يوم هاض يعني انو الزبون كل اسبوع غالبا بيجي يشتري وفي زباين بتيجي كل شهر او اكثر من شهر هاض كلو بنحط عند ال 30"
      ],
      "metadata": {
        "id": "dc960f2a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:38.282194Z",
          "iopub.execute_input": "2025-12-26T11:56:38.282549Z",
          "iopub.status.idle": "2025-12-26T11:56:38.768156Z",
          "shell.execute_reply.started": "2025-12-26T11:56:38.282514Z",
          "shell.execute_reply": "2025-12-26T11:56:38.767246Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "3: cleaning\n"
      ],
      "metadata": {
        "id": "08a9fcc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# del Full_DataSet[\"aisle\"]\n",
        "# del Full_DataSet[\"department\"]\n",
        "# del Full_DataSet[\"eval_set\"]\n",
        "\n",
        "print(Full_DataSet.isnull().sum())\n",
        "print(\"---------------------------------------\")\n",
        "\n",
        "#كان هدفي اشوف ال نان من هون بس ما زبطت ف شفتها من الملف نفسه\n",
        "Full_DataSet.head(10)\n",
        "#اللي بين معي انه ال نان بكون موجود لكل اول اوردير بطلبه المستخدم\\الزبون"
      ],
      "metadata": {
        "id": "d5b6c7b6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:38.769333Z",
          "iopub.execute_input": "2025-12-26T11:56:38.76965Z",
          "iopub.status.idle": "2025-12-26T11:56:39.239382Z",
          "shell.execute_reply.started": "2025-12-26T11:56:38.769624Z",
          "shell.execute_reply": "2025-12-26T11:56:39.238514Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def check_outliers(Full_DataSet):\n",
        "\n",
        "    out = [\"order_id\" , \"product_id\" , \"user_id\" , \"aisle_id\" , \"department_id\" , \"eval_set\"]\n",
        "    Outliers_DF = []\n",
        "    numeric_cols_all = Full_DataSet.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "\n",
        "    for i in numeric_cols_all:\n",
        "        if i not in out:\n",
        "            Outliers_DF.append(i)\n",
        "\n",
        "    col_length = len(Outliers_DF)\n",
        "    row = (col_length // 3) + 1\n",
        "    plt.figure(figsize=(20 , 5 * row))\n",
        "\n",
        "    #لاني بحتاج index + value خلال التكرار لرسم subplots.\n",
        "    #عشان هيك استخدمت enumerate\n",
        "    for i , col in enumerate(Outliers_DF):\n",
        "        plt.subplot(row , 3 , i + 1)\n",
        "\n",
        "        plot_data = Full_DataSet[col].dropna().sample(n = min(100000 , len(Full_DataSet)))\n",
        "\n",
        "        sb.boxplot(x = plot_data , color=\"lightblue\")\n",
        "        plt.title(col , fontsize = 12)\n",
        "        plt.xlabel(\" \")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "1419e778",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:39.24055Z",
          "iopub.execute_input": "2025-12-26T11:56:39.241129Z",
          "iopub.status.idle": "2025-12-26T11:56:39.248252Z",
          "shell.execute_reply.started": "2025-12-26T11:56:39.241102Z",
          "shell.execute_reply": "2025-12-26T11:56:39.247456Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#print(check_outliers(Full_DataSet))\n",
        "\n",
        "#من خلال الرسم بين معي انه الحد الفاصل بين اكبر قيمه والاوتلايرز هي 30\n",
        "Full_DataSet[\"add_to_cart_order\"] =  np.where(Full_DataSet[\"add_to_cart_order\"] > 30 , 30 , Full_DataSet[\"add_to_cart_order\"])\n",
        "#ونفس المبدأ بنطبق هون\n",
        "Full_DataSet[\"order_number\"] =  np.where(Full_DataSet[\"order_number\"] > 50 , 50 , Full_DataSet[\"order_number\"])\n",
        "\n",
        "print(Full_DataSet[\"add_to_cart_order\"].describe())\n",
        "print()\n",
        "print(Full_DataSet[\"order_number\"].describe())\n",
        "\n"
      ],
      "metadata": {
        "id": "f45b92be",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:39.249552Z",
          "iopub.execute_input": "2025-12-26T11:56:39.249887Z",
          "iopub.status.idle": "2025-12-26T11:56:40.6883Z",
          "shell.execute_reply.started": "2025-12-26T11:56:39.249859Z",
          "shell.execute_reply": "2025-12-26T11:56:40.687491Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Full_DataSet.dtypes"
      ],
      "metadata": {
        "id": "eb379afb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:40.689414Z",
          "iopub.execute_input": "2025-12-26T11:56:40.689755Z",
          "iopub.status.idle": "2025-12-26T11:56:40.696525Z",
          "shell.execute_reply.started": "2025-12-26T11:56:40.689718Z",
          "shell.execute_reply": "2025-12-26T11:56:40.69574Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy = \"constant\" , fill_value = 0)\n",
        "#بعد ما تفرجت عالداتا من الاكسل , اكتشفت انه النان موجوده بس عند اول طلب للمستخدم , يعني ما عنده طلب مسبق\n",
        "#الموديل لما يشوف الصفر رح يقلك هاض المستخدم جديد , وعشان هيك ما عنده طلبات مسبقه\n",
        "Full_DataSet[\"days_since_prior_order\"] = imputer.fit_transform(Full_DataSet[\"days_since_prior_order\"].values.reshape(-1,1))\n",
        "\n",
        "DF = pd.DataFrame(Full_DataSet , columns = Full_DataSet.columns)\n",
        "\n",
        "#DF.to_csv('archive/full_instacart_data.csv', index=False)\n",
        "print(DF.isnull().sum())\n",
        "\n"
      ],
      "metadata": {
        "id": "26e13178",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:40.697598Z",
          "iopub.execute_input": "2025-12-26T11:56:40.69789Z",
          "iopub.status.idle": "2025-12-26T11:56:41.583772Z",
          "shell.execute_reply.started": "2025-12-26T11:56:40.697866Z",
          "shell.execute_reply": "2025-12-26T11:56:41.582646Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "4: feature engineering (mandatory list)"
      ],
      "metadata": {
        "id": "5372fa85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#total orders per user يعني كل مستخدم كم مره فات المحل واشترى يعني كم طلب عملو بشكل كامل مش كم منتج اشتراه بحياتو\n",
        "# طيب هون القروب باي بيجمعلي كل الداتا تبع كل يوزر ايدي لحال\n",
        "#بعدين بقله لكل يوزر بدي كولوم الاوردر نمبر تمام هسا الاورودر نمبر لكل زبون بمثل كل زبون كم طلب عملو لحد الان فا لو اخذتلو ال ماكس\n",
        "#لو اخذت الماكس رح تعطيني رقم اخر فاتوره والي بمثل عدد الطلبات الكلي لكل زبون طيب ممكن تسالني كان بمكاني اختار كاونت مش ماكس صح كلامك لكن\n",
        "#الداتا الي عندي او كولوم الاوردر نمبر يعني بحتوي على ارقام الطلبات مش عدد الطلبات فلو اخذت كاونت رح يطلعلي عدد المنتجات مش عدد الطلباتؤ\n",
        "#استخدمنا الريست اندكس عشان يرجعلي الداتا فريم مش سيرييز لانو قروب باي بيرجع سيرييز افتراضيا وبتخرب الداتا بصير اليوزر هو كولوم الاندكس\n",
        "user_total_orders = DF.groupby('user_id')['order_number'].max().reset_index()\n",
        "# 3. بنسمي العمود اسم واضح عشان ما نتخربط بعدين\n",
        "user_total_orders.columns = ['user_id', 'user_total_orders']\n",
        "\n",
        "print(user_total_orders.head())"
      ],
      "metadata": {
        "id": "46b414ff",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:41.584943Z",
          "iopub.execute_input": "2025-12-26T11:56:41.585384Z",
          "iopub.status.idle": "2025-12-26T11:56:42.342671Z",
          "shell.execute_reply.started": "2025-12-26T11:56:41.585356Z",
          "shell.execute_reply": "2025-12-26T11:56:42.341753Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  average basket size\n",
        "#هذه الميزة بتحدد القدرة الشرائية Purchasing Power\n",
        "#وبتحدد نمط التسوق عند الزبون يعني بعرف الزبون الي عادته يشتري مثلا 50 غرض هاض زبون بمتوسط سلة كبيرة فا بهمني انو المودل ممكن\n",
        "#بهمني انو المودل ممكن يشوف هالشي ويستفيد منه بحيث لو كان شاري 3 اغراض بس يضل يقترح عليه لانو هالزبون من عادتو يشتري كثير\n",
        "\n",
        "#============================================================================================================\n",
        "\n",
        "#طيب السواال كيف بنحسبها ؟ بنحسبها عن طريق انو بنجيب لكل زبون كم المنتجات الي اشتراها بشكل كلي\n",
        "#بعدين بنجيب كم طلب عملو بشكل كلي\n",
        "#بعدين بنقسم المجموع على العدد\n",
        "#============================================================================================================\n",
        "#هون اولا عشان نجيب مجموع المنتجات الي اشتراها كل زبون بنجيب كولوم البروودكت ايدي وبنعمللو كاونت هيك بنعد كل المنتجات الي اشتراها\n",
        "#بعدين بنجيب كولوم الاوردر نمبر وبناخد الماكس زي ما شرحنا فوق عشان نعرف كم طلب عملو بشكل كلي\n",
        "\n",
        "#واستخدمنا ميثود الاقريقيت الي بتتيحلي اعمل اكشنز متعدده على كولمز مختلفه بنفس الوقت بدل ما اعمل قروب باي مرتين\n",
        "basket_data = DF.groupby('user_id').agg({ 'product_id':'count', 'order_number': 'max'}).reset_index()\n",
        "\n",
        "# مجرد تسميت الكولمز بشكل واضح بس\n",
        "basket_data.columns = ['user_id', 'total_items_bought', 'total_orders_made']\n",
        "\n",
        "#الحسبه\n",
        "basket_data['avg_basket_size'] = basket_data['total_items_bought'] / basket_data['total_orders_made']\n",
        "\n",
        "print(basket_data.head())"
      ],
      "metadata": {
        "id": "6e8efa8b",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:42.343723Z",
          "iopub.execute_input": "2025-12-26T11:56:42.343995Z",
          "iopub.status.idle": "2025-12-26T11:56:43.243591Z",
          "shell.execute_reply.started": "2025-12-26T11:56:42.343971Z",
          "shell.execute_reply": "2025-12-26T11:56:43.242807Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  User-Level Features full\n",
        "#هون لازم نعمل سورت اول عشان اخر مطلوب اللاست لاخر طلب فا ممكن يكون اخر طلب الي بجيبو مش هو اخر طلب عملو\n",
        "#بس الجهاز عندي بتحملش\n",
        "# Full_DataSet.sort_values(['user_id', 'order_number'], inplace=True)\n",
        "user_features = DF.groupby('user_id').agg({\n",
        "      # 1. Total #Orders\n",
        "    'order_number': 'max',\n",
        "    # 2. هاض بساعدنا نعرف كم منتج اشتراها كل زبون بشكل كلي\n",
        "     'product_id': 'count',\n",
        "    # 3. Reorder Ratio\n",
        "    'reordered': 'mean',\n",
        "\n",
        "   #هون حسبنا اخر مطلوبين بخطوه وحده بدل ما نعمل قروب باي مرتين\n",
        "    'days_since_prior_order': ['mean', 'last']\n",
        "}).reset_index()\n",
        "\n",
        "\n",
        "user_features.columns = ['user_id',  'user_total_orders',  'user_total_items', 'user_reorder_ratio','user_avg_days_between', 'user_days_since_last_order'  ]\n",
        "\n",
        "# Basket Size\n",
        "user_features['user_avg_basket_size'] = user_features['user_total_items'] / user_features['user_total_orders']\n",
        "\n",
        "#هاض العامود مش ضروري بعد ما حسبنا الافريج مابنحتاجه\n",
        "del user_features['user_total_items']\n",
        "\n",
        "display(user_features.head())"
      ],
      "metadata": {
        "id": "339a4785",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:43.244639Z",
          "iopub.execute_input": "2025-12-26T11:56:43.244933Z",
          "iopub.status.idle": "2025-12-26T11:56:45.308116Z",
          "shell.execute_reply.started": "2025-12-26T11:56:43.244899Z",
          "shell.execute_reply": "2025-12-26T11:56:45.30745Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Product-level features"
      ],
      "metadata": {
        "id": "dba2c5a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Product-Level Features ---\n",
        "\n",
        "# هالمره التجميع رح يكون حسب المنتج مش حسب اليوزر\n",
        "product_features = DF.groupby('product_id').agg({\n",
        "\n",
        "    #  Popularity\n",
        "    #هون شو ممكن يفيدنا هون قصدو من البوبولاريتي انه نعرف كم مرة انباع هاد المنتج ممكن من خلاله نعرف  اكثر المنتجات بينباع او وين اقل منتج\n",
        "    'user_id': 'count',\n",
        "    # ليش user_id؟ وليش count؟\n",
        "    # عشان نعد كم زبون اشترى هاد المنتج لانو كل سطر بيمثل  عنا عمليه شراء.\n",
        "    #====================================================================================\n",
        "    #  Reorder Rate\n",
        "    #هون بنحسب نسبة اعادة الطلبات للمنتج\n",
        "    'reordered': 'mean',\n",
        "    #هاي واضحه من اسمها بدهاش اشي\n",
        "    #====================================================================================\n",
        "    # Average  Position\n",
        "    #طيب ممكن تسالني ليش اخترنا هاض الكولوم بالذات رح لانه بمثل ترتيب المنتج داخل السلة فلو اخذنا المين رح يعطينا ترتيب المنتج داخل السلة زي ماهو طالب\n",
        "    'add_to_cart_order': 'mean'\n",
        "\n",
        "}).reset_index()\n",
        "\n",
        "product_features.columns = [ 'product_id', 'product_total_purchases', 'product_reorder_rate', 'product_avg_cart_position' ]\n",
        "\n",
        "display(product_features.head())"
      ],
      "metadata": {
        "id": "4ac0a591",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:45.309067Z",
          "iopub.execute_input": "2025-12-26T11:56:45.309394Z",
          "iopub.status.idle": "2025-12-26T11:56:46.714045Z",
          "shell.execute_reply.started": "2025-12-26T11:56:45.309354Z",
          "shell.execute_reply": "2025-12-26T11:56:46.713223Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "User×Product interaction features"
      ],
      "metadata": {
        "id": "55efd949"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#UserxProduct Interaction Features\n",
        "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
        "\n",
        "#دمجتها من هسا عشان اجرب اشغل user_days_since_last_order لانها مش جزء من الداتا الاساسيه ف ما اشتغل الكود\n",
        "DF = DF.merge(user_features[['user_id' , 'user_days_since_last_order']] , on = 'user_id', how = 'left')\n",
        "\n",
        "\n",
        "uxp_features = DF.groupby(['user_id', 'product_id']).agg({\n",
        "# Total Purchases of Product by User\n",
        "#هون عشان نجيبها كان ممكن نستخدم اي عمود بس بدنا واحد  بس المهم نعد كم مرة هاد الزبون اشترا هاد المنتج\n",
        "#طب ليش اخترت هاض الكولوم بالذات اختصارا للوقت بس عشان المطلوب الثاني رح ارجع اطلبه تمام\n",
        "#====================================================================================\n",
        "\n",
        "# Reorder Probability of Product by User\n",
        "#هون استخدمنا برضو بنفس العامود بس اخذنا المين عشان يعطينا النسبة الي طلبها الزبون من هاد المنتج\n",
        "    'reordered': ['count', 'mean'],\n",
        "\n",
        "    'user_days_since_last_order': 'max'    # هاي مش عارف اعملها علقت كيف ممكن نجيب ال   days since last purchase by     user_days_since_last_order  days_since_prior_order\n",
        "}).reset_index()\n",
        "\n",
        "# 2. تسمية الأعمدة بشكل واضح (عشان الدكتور يفهم كل عمود شو هو)\n",
        "uxp_features.columns = [\n",
        "    'user_id',\n",
        "    'product_id',\n",
        "    'uxp_total_bought',\n",
        "    'uxp_reorder_ratio',\n",
        "    'uxp_days_last_order_'\n",
        "]\n",
        "\n",
        "display(uxp_features.head(20))"
      ],
      "metadata": {
        "id": "77231b20",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:56:46.715095Z",
          "iopub.execute_input": "2025-12-26T11:56:46.715612Z",
          "iopub.status.idle": "2025-12-26T11:57:04.800005Z",
          "shell.execute_reply.started": "2025-12-26T11:56:46.715584Z",
          "shell.execute_reply": "2025-12-26T11:57:04.7992Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Temporal features: hour/day/month/year, season, holiday flags (if available)."
      ],
      "metadata": {
        "id": "bc48c8af"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# طيب هون المطلوب منا بالتيمبورال فيشترز انو نزبط الوقت مثلا نخليه صبح ومسا ومثلا الايام نقسمها ايام عاديه وايام عطله والشهر\n",
        "#بس مبادايا الشهر والسنه والموسم مابنقدر لانو مامعنا معلومات عنها  في رح نكتفي بالساعات واليوم\n",
        "#نبدا بالساعات هسا التوقيت  عنا من 0 ل 23 فممكن نقسمهم لثلاث فترات\n",
        "def time_of_day(hour):\n",
        "    if 5 <= hour < 12:\n",
        "        return 'Morning'\n",
        "    elif 12 <= hour < 17:\n",
        "        return 'Afternoon'\n",
        "    elif 17 <= hour < 21:\n",
        "        return 'Evening'\n",
        "    else:\n",
        "        return 'Midnight'\n",
        "DF['time_of_day'] = DF['order_hour_of_day'].apply(time_of_day)\n",
        "print(DF['time_of_day'].head(10))\n",
        "print(\"==\"*40)\n",
        "#طيب قلنا للايام بنقسمها لايام عاديه وايام عطله\n",
        "#وزي مابنعرف بالداتا الي عندي السبت والاحد همه العطله فرقمهم بكون 0 و 1\n",
        "#هون اختصارا على حالنا لقدام خليت الكولوم الجديد عباره عن ارقام 0 و 1 بدل ما اخليها نصوص عشان اسهل التعامل معها بعدين\n",
        "def day_type(day):\n",
        "    if (day == 0) or (day == 1):\n",
        "        return 1 # طبعا واحد بتعني انها شسمو ويكند\n",
        "    else:\n",
        "        return 0\n",
        "DF['is_weekend'] = DF['order_dow'].apply(day_type)\n",
        "print(DF['is_weekend'].head(30))\n",
        "#حطيت 30 لانو خفت كلها صفار ههههه يسعد ربك\n"
      ],
      "metadata": {
        "id": "796fe777",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:57:04.801075Z",
          "iopub.execute_input": "2025-12-26T11:57:04.801406Z",
          "iopub.status.idle": "2025-12-26T11:57:24.162225Z",
          "shell.execute_reply.started": "2025-12-26T11:57:04.801368Z",
          "shell.execute_reply": "2025-12-26T11:57:24.161256Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Aggregations over Windows (Last 3 Orders) - بدون Lambda ---\n",
        "\n",
        "# 1. تجهيز الداتا: بنحسب حجم السلة لكل طلب (جدول صغير وخفيف)\n",
        "orders_summary = DF.groupby(['user_id', 'order_number']).size().reset_index(name='basket_size')\n",
        "\n",
        "# 2. الترتيب (مهم جداً): عشان لما نقول \"آخر 3\" يكونوا عنجد آخر 3 زمنياً\n",
        "orders_summary = orders_summary.sort_values(['user_id', 'order_number'])\n",
        "\n",
        "# 3. تعريف الفنكشن العادي (بدل اللمدا)\n",
        "# هذا الفنكشن بياخذ عمود أرقام، وبحسب المتوسط المتحرك لآخر 3 قيم\n",
        "def calculate_last_3_avg(series):\n",
        "    # window=3: يعني خذ 3 قيم\n",
        "    # min_periods=1: يعني حتى لو الزبون عنده طلب واحد بس، احسبله المعدل (ما ترجع Null)\n",
        "    return series.rolling(window=3, min_periods=1).mean()\n",
        "\n",
        "# 4. تطبيق الفنكشن على كل زبون\n",
        "# transform: بتمسك الفنكشن اللي كتبناه فوق، وبتطبقه على كل \"مجموعة\" (زبون)\n",
        "orders_summary['rolling_avg_3_orders'] = orders_summary.groupby('user_id')['basket_size'].transform(calculate_last_3_avg)\n",
        "\n",
        "# 5. النتيجة النهائية\n",
        "# احنا بهمنا \"آخر وضع\" وصله الزبون، فبناخذ آخر سطر لكل زبون\n",
        "user_window_features = orders_summary.groupby('user_id').last().reset_index()\n",
        "\n",
        "# ترتيب وتنظيف الجدول النهائي\n",
        "user_window_features = user_window_features[['user_id', 'rolling_avg_3_orders']]\n",
        "user_window_features.columns = ['user_id', 'u_avg_basket_last_3']\n",
        "\n",
        "display(user_window_features.head(20))"
      ],
      "metadata": {
        "id": "31d0e9eb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:57:24.163449Z",
          "iopub.execute_input": "2025-12-26T11:57:24.163817Z",
          "iopub.status.idle": "2025-12-26T11:58:07.529003Z",
          "shell.execute_reply.started": "2025-12-26T11:57:24.163777Z",
          "shell.execute_reply": "2025-12-26T11:58:07.528045Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ تم حساب (Rolling Window) باستخدام فنكشن عادي!"
      ],
      "metadata": {
        "id": "8ba4a0f9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At least one engineered non-linear feature : log transforms"
      ],
      "metadata": {
        "id": "5ff55361"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# افترض إنك حسبت user_features في الخطوة الأولى\n",
        "# بدنا نحول عمود \"عدد الطلبات\" باستخدام اللوغاريتم\n",
        "#هسا\n",
        "print(\"=\")\n",
        "#هون طقعت ديسبلاي لانها اوضح بس من برنت\n",
        "user_features['u_total_orders_log'] = np.log(user_features['user_total_orders'])\n",
        "\n",
        "# حطيناهم جمب بعض عشان تشوف الفرق\n",
        "print(\"user_total_orders trasform\")\n",
        "display(user_features[['user_total_orders', 'u_total_orders_log']].head(90))\n",
        "#\n",
        "#كمان فيتشر ثاني نعملو مش غلط\n",
        "product_features['p_total_purchases_log'] = np.log(product_features['product_total_purchases'])\n",
        "\n",
        "print(\"=\"*40)\n",
        "print(\"product_ total_purchases transform\")\n",
        "\n",
        "display(product_features[['product_total_purchases', 'p_total_purchases_log']].head())"
      ],
      "metadata": {
        "id": "8fff0338",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:07.53029Z",
          "iopub.execute_input": "2025-12-26T11:58:07.530642Z",
          "iopub.status.idle": "2025-12-26T11:58:07.558217Z",
          "shell.execute_reply.started": "2025-12-26T11:58:07.530606Z",
          "shell.execute_reply": "2025-12-26T11:58:07.557412Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#بدي اسوي نسخه للاحتياط , هسا انا صرت بمرحله حرجه شوي و اي خطأ ممكن يدمر الداتا كامله ف الاحتياط واجب\n",
        "final_df = DF.copy()\n",
        "\n",
        "final_df = final_df.merge(user_features , on = 'user_id' , how = 'left')\n",
        "#لاني دمجتهم من قبل , عملت هالحركه عشان اتأكد ما يصير عندي اي تكرار\n",
        "final_df = final_df.drop(columns=[col for col in user_features.columns if col in final_df.columns and col != 'user_id'])\n",
        "\n",
        "final_df = final_df.merge(user_features , on = 'user_id', how = 'left')\n",
        "final_df = final_df.merge(product_features , on = 'product_id', how = 'left')\n",
        "final_df = final_df.merge(uxp_features , on = ['user_id' , 'product_id'] , how = 'left')\n",
        "final_df = final_df.merge(user_window_features , on = 'user_id' , how = 'left')"
      ],
      "metadata": {
        "id": "1f5fa79c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:07.558991Z",
          "iopub.execute_input": "2025-12-26T11:58:07.559251Z",
          "iopub.status.idle": "2025-12-26T11:58:55.077458Z",
          "shell.execute_reply.started": "2025-12-26T11:58:07.559228Z",
          "shell.execute_reply": "2025-12-26T11:58:55.07644Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_df.shape)\n",
        "print(DF.shape)\n",
        "print()\n",
        "print(final_df.isnull().sum())\n",
        "final_df.head()"
      ],
      "metadata": {
        "id": "56f347b8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:55.078648Z",
          "iopub.execute_input": "2025-12-26T11:58:55.079042Z",
          "iopub.status.idle": "2025-12-26T11:58:57.99852Z",
          "shell.execute_reply.started": "2025-12-26T11:58:55.079001Z",
          "shell.execute_reply": "2025-12-26T11:58:57.997718Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#بدي اختار الاعمده اللي لازم ازبط الميموري الهم\n",
        "final_df.info()"
      ],
      "metadata": {
        "id": "b87833c0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:57.999445Z",
          "iopub.execute_input": "2025-12-26T11:58:57.999722Z",
          "iopub.status.idle": "2025-12-26T11:58:58.011668Z",
          "shell.execute_reply.started": "2025-12-26T11:58:57.999674Z",
          "shell.execute_reply": "2025-12-26T11:58:58.010695Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_memory_FE(df , col_name):\n",
        "\n",
        "    for col in col_name:\n",
        "        col_type = df[col].dtype\n",
        "\n",
        "        if \"int\" in str(col_type):\n",
        "            df[col] = df[col].astype(\"int32\")\n",
        "\n",
        "        elif \"float\" in str(col_type):\n",
        "            df[col] = df[col].astype(\"float32\")\n",
        "\n",
        "        elif col_type == \"object\":\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    return df\n",
        "# import numpy as np\n",
        "\n",
        "# def reduce_memory_FE(df, col_name):\n",
        "#     for col in col_name:\n",
        "#         # تأكد إن العمود موجود أصلاً عشان ما يضرب إيرور\n",
        "#         if col not in df.columns:\n",
        "#             continue\n",
        "\n",
        "#         col_type = df[col].dtype\n",
        "\n",
        "#         # التعامل مع الأرقام الصحيحة\n",
        "#         if str(col_type)[:3] == 'int':\n",
        "#             c_min = df[col].min()\n",
        "#             c_max = df[col].max()\n",
        "\n",
        "#             # إذا الرقم صغير (زي أيام الأسبوع أو الساعات) حوله لـ int8\n",
        "#             if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "#                 df[col] = df[col].astype(np.int8)\n",
        "#             # إذا أكبر شوي حوله لـ int16\n",
        "#             elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "#                 df[col] = df[col].astype(np.int16)\n",
        "#             # غير هيك خليه int32\n",
        "#             else:\n",
        "#                 df[col] = df[col].astype(np.int32)\n",
        "\n",
        "#         # التعامل مع الكسور (ثبتها على float32 ممتاز)\n",
        "#         elif 'float' in str(col_type):\n",
        "#             df[col] = df[col].astype(np.float32)\n",
        "\n",
        "#         # التعامل مع النصوص\n",
        "#         elif col_type == \"object\":\n",
        "#             df[col] = df[col].astype(\"category\")\n",
        "\n",
        "#     return df\n",
        "\n",
        "# # القائمة تبعتك\n",
        "# col_name = [\"uxp_reorder_ratio\" , \"u_avg_basket_last_3\" , \"uxp_total_bought\" ,\n",
        "#             \"p_total_purchases_log\" , \"product_avg_cart_position\" , \"product_reorder_rate\" ,\n",
        "#             \"product_total_purchases\" , \"u_total_orders_log\" , \"user_avg_basket_size\" ,\n",
        "#             \"user_reorder_ratio\" , \"is_weekend\" , \"time_of_day\"]\n",
        "\n",
        "# # ⚠️ انتبه: تأكد هل اسم الداتا فريم عندك DF ولا final_df ؟\n",
        "# # حسب الخطوات اللي مشينا عليها قبل شوي، المفروض اسمها DF\n",
        "# DF = reduce_memory_FE(DF, col_name)\n",
        "\n",
        "# print(\"✅ تم ضغط أعمدة الـ Features بذكاء!\")\n",
        "# print(DF[col_name].dtypes) # عشان تتأكد بعينك"
      ],
      "metadata": {
        "id": "fdac7c25",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:58.012987Z",
          "iopub.execute_input": "2025-12-26T11:58:58.013363Z",
          "iopub.status.idle": "2025-12-26T11:58:58.032708Z",
          "shell.execute_reply.started": "2025-12-26T11:58:58.013327Z",
          "shell.execute_reply": "2025-12-26T11:58:58.031771Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "col_name = [\"uxp_reorder_ratio\" , \"u_avg_basket_last_3\" , \"uxp_total_bought\" , \"p_total_purchases_log\" , \"product_avg_cart_position\" , \"product_reorder_rate\" , \"product_total_purchases\" , \"u_total_orders_log\" , \"user_avg_basket_size\" , \"user_reorder_ratio\" , \"is_weekend\" , \"time_of_day\"]\n",
        "\n",
        "final_df = reduce_memory_FE(final_df, col_name)"
      ],
      "metadata": {
        "id": "fae4c2a9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:58:58.033656Z",
          "iopub.execute_input": "2025-12-26T11:58:58.033887Z",
          "iopub.status.idle": "2025-12-26T11:59:01.617517Z",
          "shell.execute_reply.started": "2025-12-26T11:58:58.033866Z",
          "shell.execute_reply": "2025-12-26T11:59:01.616541Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.info()"
      ],
      "metadata": {
        "id": "e3da99f4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:01.618553Z",
          "iopub.execute_input": "2025-12-26T11:59:01.618816Z",
          "iopub.status.idle": "2025-12-26T11:59:01.631411Z",
          "shell.execute_reply.started": "2025-12-26T11:59:01.618792Z",
          "shell.execute_reply": "2025-12-26T11:59:01.630546Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = final_df.drop(columns=['user_days_since_last_order_x' ,\n",
        "                                  'user_days_since_last_order_y'] ,\n",
        "    errors='ignore'\n",
        ")\n",
        "\n",
        "#ما عرفت اقلل الذاكره اكثر من هيك 😢\n",
        "final_df.info()"
      ],
      "metadata": {
        "id": "dacc11e6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:01.632535Z",
          "iopub.execute_input": "2025-12-26T11:59:01.632881Z",
          "iopub.status.idle": "2025-12-26T11:59:03.660622Z",
          "shell.execute_reply.started": "2025-12-26T11:59:01.632844Z",
          "shell.execute_reply": "2025-12-26T11:59:03.659641Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#final_df.to_csv('archive/new_instacart_data.csv', index=False)"
      ],
      "metadata": {
        "id": "61ca72fc",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:03.661785Z",
          "iopub.execute_input": "2025-12-26T11:59:03.662387Z",
          "iopub.status.idle": "2025-12-26T11:59:03.665906Z",
          "shell.execute_reply.started": "2025-12-26T11:59:03.662351Z",
          "shell.execute_reply": "2025-12-26T11:59:03.665154Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "5: Dimensionality & collinearity"
      ],
      "metadata": {
        "id": "1c4a7bcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_cols = ['order_id', 'user_id', 'product_id', 'aisle_id', 'department_id']\n",
        "low_cols = [\"department_id\", \"order_dow\" , \"time_of_day\"]\n",
        "high_cols = [\"user_id\", \"product_id\", \"aisle_id\"]\n",
        "\n",
        "final_df[high_cols] = final_df[high_cols].astype(str)\n",
        "#هالحركه سويتها بعد ما متت وانا بحلل الكود بعد ما طلعلي التنبيه هاض\n",
        "#Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
        "#لما راجعت الانكوديرز تذكرت انه التارقيت ما بشتغل غير مع نصوص والاعمده اللي انا معطيه اياهم رقميات\n",
        "\n",
        "# target_col = \"reordered\"\n",
        "# Frequency_col = \"product_name\"\n",
        "\n",
        "# #عدد الاعمده كبير جدا فقلت بعمل لوب + استثناءات عشان اريح راسي\n",
        "# num_cols = (final_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "# num_cols = [c for c in num_cols if c not in id_cols]"
      ],
      "metadata": {
        "id": "388e21eb",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:03.666903Z",
          "iopub.execute_input": "2025-12-26T11:59:03.667235Z",
          "iopub.status.idle": "2025-12-26T11:59:33.712286Z",
          "shell.execute_reply.started": "2025-12-26T11:59:03.667166Z",
          "shell.execute_reply": "2025-12-26T11:59:33.711377Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "target_col = \"reordered\"\n",
        "Frequency_col = \"product_name\"\n",
        "\n",
        "#عدد الاعمده كبير جدا فقلت بعمل لوب + استثناءات عشان اريح راسي\n",
        "num_cols = (final_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "num_cols = [c for c in num_cols if c not in id_cols]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:33.713452Z",
          "iopub.execute_input": "2025-12-26T11:59:33.713731Z",
          "iopub.status.idle": "2025-12-26T11:59:41.192687Z",
          "shell.execute_reply.started": "2025-12-26T11:59:33.713704Z",
          "shell.execute_reply": "2025-12-26T11:59:41.191514Z"
        },
        "id": "58fb6699-c709-4ceb-883b-972efef4bea8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#بدي استخدم VIF , هاض عباره عن فنكشن رياضي ببين قديش في ارتباط وتكرار بين الاعمده نفسهم\n",
        "#الهدف منه اني اشوف شو في اعمده فيهم تشابه كبير وبقدمو نفس المعلومه تقريبا عشان احذف واحد منهم\n",
        "\n",
        "SAMPLE_SIZE = 50000\n",
        "V = final_df[num_cols].sample(n=SAMPLE_SIZE , random_state = 42)\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif[\"feature\"] = V[num_cols].columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(V.values , i) for i in range(V.shape[1])]\n",
        "\n",
        "#تحت 5 ممتاز\n",
        "#بين ال 6 وال 10 مقبول\n",
        "#اكثر من هيك بدك تشوف شو و وين في ترابط غير مهم وتبلش تحذف\n",
        "#ال inf حذف مباشره\n",
        "\n",
        "vif.sort_values(\"VIF\" , ascending = True)"
      ],
      "metadata": {
        "id": "653b1743",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:41.19413Z",
          "iopub.execute_input": "2025-12-26T11:59:41.194645Z",
          "iopub.status.idle": "2025-12-26T11:59:45.061198Z",
          "shell.execute_reply.started": "2025-12-26T11:59:41.194604Z",
          "shell.execute_reply": "2025-12-26T11:59:45.060424Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vif[\"feature\"] = V[num_cols].columns\n",
        "vif[\"VIF\"] = [variance_inflation_factor(V.values , i) for i in range(V.shape[1])]\n",
        "\n",
        "#تحت 5 ممتاز\n",
        "#بين ال 6 وال 10 مقبول\n",
        "#اكثر من هيك بدك تشوف شو و وين في ترابط غير مهم وتبلش تحذف\n",
        "#ال inf حذف مباشره\n",
        "\n",
        "vif.sort_values(\"VIF\" , ascending = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:45.063467Z",
          "iopub.execute_input": "2025-12-26T11:59:45.063791Z",
          "iopub.status.idle": "2025-12-26T11:59:45.88303Z",
          "shell.execute_reply.started": "2025-12-26T11:59:45.063742Z",
          "shell.execute_reply": "2025-12-26T11:59:45.881607Z"
        },
        "id": "f8fd16a0-0e5e-4a6a-bc1d-aa6360aa674f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (8 , 5))\n",
        "plt.scatter(vif[\"VIF\"] , vif[\"feature\"])\n",
        "plt.axvline(10 , color = 'red' , linestyle = '--')\n",
        "plt.xlabel(\"VIF\")\n",
        "plt.title(\"VIF Scatter Plot\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6e1eb004",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:45.883845Z",
          "iopub.execute_input": "2025-12-26T11:59:45.884111Z",
          "iopub.status.idle": "2025-12-26T11:59:46.110516Z",
          "shell.execute_reply.started": "2025-12-26T11:59:45.884084Z",
          "shell.execute_reply": "2025-12-26T11:59:46.109724Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#حذفت القيم اللانهائيه , والقيم اللي فيها النسبه عاليه , لانهم بدلو على تكرار وتشابه المعلومات , يعني لو خليتهم كلهم زي كأني مكرر نفس العامود ما فرقت\n",
        "drop_cols = [\n",
        "    \"user_days_since_last_order\" ,\n",
        "    \"uxp_days_last_order_\" ,\n",
        "    #u_total_orders_log كنت بدي اخليه بما انه تعبنا عليه بمرحلة الهندسه بس النسبه فيه كانت كثير عاليه :(\n",
        "    \"user_total_orders\" ,\n",
        "\n",
        "    \"product_avg_cart_position\" ,\n",
        "    \"product_reorder_rate\" ,\n",
        "    \"user_reorder_ratio\" ]\n",
        "\n",
        "final_df = final_df.drop(columns = drop_cols , errors=\"ignore\")\n",
        "\n",
        "#صار عندي ايرور بالبريبروسيسر لانه الداتا صار فيها عدم تطابق بعد الدروب ف بدي ارجع انسخ الاعمده كمان مره\n",
        "num_cols = (final_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "num_cols = [c for c in num_cols if c not in id_cols]"
      ],
      "metadata": {
        "id": "0f310ebf",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:46.111581Z",
          "iopub.execute_input": "2025-12-26T11:59:46.111854Z",
          "iopub.status.idle": "2025-12-26T11:59:55.211599Z",
          "shell.execute_reply.started": "2025-12-26T11:59:46.111829Z",
          "shell.execute_reply": "2025-12-26T11:59:55.210677Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "6+7: preprocessing and scaling"
      ],
      "metadata": {
        "id": "542dcb37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def best_params_for_TE(DF , high_cols):\n",
        "\n",
        "    #المشكله اللي صارت انه لما اقسم الداتا , لسا ما شغل البريبروسيسر عليها ف لسا مش كل الفيتشرز تحولو لقيم رقميه\n",
        "    del DF[\"product_name\"]\n",
        "\n",
        "    unique_users = DF['user_id'].unique()\n",
        "    selected_users = np.random.choice(unique_users, size=3000, replace=False)\n",
        "    #رفعت عدد العينات ل 5000 والكود طول لتنه اشتغل ف عشان هيك قللتهم ك حل وسط وهون طلع معي افضل نتيجع بعد عدة تكرارات\n",
        "\n",
        "    df_check = DF[DF['user_id'].isin(selected_users)].copy()\n",
        "\n",
        "    df_check[high_cols] = df_check[high_cols].astype(str)\n",
        "\n",
        "    xc = df_check.drop(\"reordered\", axis=1)\n",
        "    yc = df_check['reordered']\n",
        "\n",
        "    xc_train , xc_test , yc_train , yc_test = train_test_split(xc , yc , test_size = 0.2 , random_state = 42)\n",
        "\n",
        "    pipeline = make_pipeline(\n",
        "        ce.TargetEncoder(cols=high_cols) ,\n",
        "        RandomForestClassifier(\n",
        "            n_estimators = 100,  # عدد الأشجار\n",
        "            max_depth = 10 ,      # عمق الشجرة (عشان ما ياخذ وقت طويل)\n",
        "            random_state = 42 ,\n",
        "            n_jobs = -1\n",
        "        )\n",
        "    )\n",
        "\n",
        "    param_grid = {\n",
        "        'targetencoder__smoothing': [1, 10, 50] ,\n",
        "        'targetencoder__min_samples_leaf': [1, 20]\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        estimator = pipeline ,\n",
        "        param_grid = param_grid ,\n",
        "        cv = 3 ,\n",
        "        scoring = 'roc_auc' ,\n",
        "        verbose = 1\n",
        "    )\n",
        "\n",
        "    print(\"\\n\")\n",
        "    grid_search.fit(xc_train, yc_train)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 30)\n",
        "    print(f\"Best ROC_AUC: {grid_search.best_score_:.4f}\")\n",
        "    print(\"Best Parameters:\")\n",
        "    print(grid_search.best_params_)\n",
        "\n",
        "    #تجربه فاشله لتحديد افضل المعاملات\n",
        "    #السبب انه عدد العينات كبير نسبيا ومدامني بجرب كل رقم بلوب لحال ف رح يوخذ مني وقت كبيييييير جدااااا\n",
        "    '''\n",
        "    smoothing_op = [1, 2, 10, 20, 50, 100]\n",
        "    leaf_op = [1, 5, 10, 20, 50]\n",
        "    Kfold_op = [3, 5, 10]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for k in Kfold_op:\n",
        "        current_kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "        for sm in smoothing_op:\n",
        "            for leaf in leaf_op:\n",
        "\n",
        "                encoder = ce.TargetEncoder(\n",
        "                    cols=high_cols,\n",
        "                    min_samples_leaf=leaf,\n",
        "                    smoothing=sm\n",
        "                )\n",
        "\n",
        "                model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "                pipeline = make_pipeline(encoder, model)\n",
        "\n",
        "                try:\n",
        "                    scores = cross_val_score(pipeline, xc, yc, cv=current_kf, scoring=\"roc_auc\")\n",
        "                    mean_auc = scores.mean()\n",
        "                    std_auc = scores.std()\n",
        "\n",
        "                    results.append({\n",
        "                        'n_splits': k,\n",
        "                        'smoothing': sm,\n",
        "                        'min_samples_leaf': leaf,\n",
        "                        'auc_mean': mean_auc,\n",
        "                        'auc_std': std_auc\n",
        "                    })\n",
        "\n",
        "                    print(f\"K={k}, Smooth={sm}, Leaf={leaf} -> AUC: {mean_auc:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error at K={k}, Smooth={sm}, Leaf={leaf}: {e}\")\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    sorted_results = results_df.sort_values(by='auc_mean', ascending=False)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"TOP 3 PARAMETER COMBINATIONS:\")\n",
        "    print(sorted_results.head(3))\n",
        "    print()\n",
        "\n",
        "    if not sorted_results.empty:\n",
        "        best_params = sorted_results.iloc[0]\n",
        "        print(f\"\\nthe best:\\nSmoothing: {best_params['smoothing']}\\nMin Samples Leaf: {best_params['min_samples_leaf']}\\nK-Fold Splits: {int(best_params['n_splits'])}\")\n",
        "    '''"
      ],
      "metadata": {
        "id": "50781d9a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:55.213035Z",
          "iopub.execute_input": "2025-12-26T11:59:55.213322Z",
          "iopub.status.idle": "2025-12-26T11:59:55.222639Z",
          "shell.execute_reply.started": "2025-12-26T11:59:55.213295Z",
          "shell.execute_reply": "2025-12-26T11:59:55.221664Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#حذفت القيم اللانهائيه , والقيم اللي فيها النسبه عاليه , لانهم بدلو على تكرار وتشابه المعلومات , يعني لو خليتهم كلهم زي كأني مكرر نفس العامود ما فرقت\n",
        "drop_cols = [\n",
        "    \"user_days_since_last_order\" ,\n",
        "    \"uxp_days_last_order_\" ,\n",
        "    #u_total_orders_log كنت بدي اخليه بما انه تعبنا عليه بمرحلة الهندسه بس النسبه فيه كانت كثير عاليه :(\n",
        "    \"user_total_orders\" ,\n",
        "\n",
        "    \"product_avg_cart_position\" ,\n",
        "    \"product_reorder_rate\" ,\n",
        "    \"user_reorder_ratio\" ]\n",
        "\n",
        "final_df = final_df.drop(columns = drop_cols , errors=\"ignore\")\n",
        "\n",
        "#صار عندي ايرور بالبريبروسيسر لانه الداتا صار فيها عدم تطابق بعد الدروب ف بدي ارجع انسخ الاعمده كمان مره\n",
        "num_cols = (final_df.drop(columns=[target_col]).select_dtypes(include=[\"int32\" , \"float32\"]).columns.tolist())\n",
        "num_cols = [c for c in num_cols if c not in id_cols]"
      ],
      "metadata": {
        "id": "56769264",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T11:59:55.223744Z",
          "iopub.execute_input": "2025-12-26T11:59:55.224064Z",
          "iopub.status.idle": "2025-12-26T12:00:04.330194Z",
          "shell.execute_reply.started": "2025-12-26T11:59:55.224029Z",
          "shell.execute_reply": "2025-12-26T12:00:04.32923Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def which_scaler(num_cols):\n",
        "\n",
        "    SAMPLE_SIZE = 500000\n",
        "    df_sampled = DF.sample(n=SAMPLE_SIZE, random_state=42).copy()\n",
        "\n",
        "    fig, axes = plt.subplots(len(num_cols), 2, figsize=(14, 4 * len(num_cols)))\n",
        "    plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
        "\n",
        "    for i, col in enumerate(num_cols):\n",
        "\n",
        "        sns.histplot(\n",
        "            df_sampled[col],\n",
        "            kde=True,\n",
        "            ax=axes[i, 0],\n",
        "            color='skyblue',\n",
        "            edgecolor='black',\n",
        "            line_kws={'linewidth': 3}\n",
        "        )\n",
        "        axes[i, 0].set_title(f'Distribution of {col}', fontsize=12)\n",
        "        axes[i, 0].set_xlabel(col, fontsize=10)\n",
        "        axes[i, 0].grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "        stats.probplot(\n",
        "            df_sampled[col].dropna(),\n",
        "            dist=\"norm\",\n",
        "            plot=axes[i, 1]\n",
        "        )\n",
        "        axes[i, 1].set_title(f'Q-Q Plot of {col}', fontsize=12)\n",
        "        axes[i, 1].set_xlabel('Theoretical Quantiles (Normal)', fontsize=10)\n",
        "        axes[i, 1].set_ylabel('Sample Quantiles', fontsize=10)\n",
        "\n",
        "    plt.savefig('numerical_features_distribution_analysis.png', bbox_inches='tight')\n",
        "    print(\"تم حفظ تحليل التوزيعات في 'numerical_features_distribution_analysis.png'\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6791e61a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.33129Z",
          "iopub.execute_input": "2025-12-26T12:00:04.331564Z",
          "iopub.status.idle": "2025-12-26T12:00:04.339683Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.33154Z",
          "shell.execute_reply": "2025-12-26T12:00:04.338947Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "num_cols = [\"order_hour_of_day\", \"days_since_prior_order\", \"add_to_cart_order\", \"order_number\"]\n",
        "low_cols = [\"department_id\", \"order_dow\"]\n",
        "high_cols = [\"user_id\", \"product_id\", \"aisle_id\"]\n",
        "target_col = \"reordered\"\n",
        "Frequency_col = \"product_name\"\n",
        "\n",
        "#الرسم ببينلك انه التوزيع مبعثر وغير طبيعي وبحتوي على اوتلايرز كثيييييررر ,  عشان هيك كان افضل خيار استخدام\n",
        "#SD لانه افضل بالتعامل مع الاوتلايرز وما بتأثر فيهم بشكل واضح وسلبي\n",
        "\n",
        "#which_scaler(num_cols)\n",
        "'''"
      ],
      "metadata": {
        "id": "9b074bb0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.340735Z",
          "iopub.execute_input": "2025-12-26T12:00:04.340982Z",
          "iopub.status.idle": "2025-12-26T12:00:04.364032Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.340959Z",
          "shell.execute_reply": "2025-12-26T12:00:04.36319Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "اللي قاعد بصير هسا اني نقلت الانكوديرز لبعد مرحلة الهندسه , ليش ؟\n",
        "لانه بكل بساطه احترت كيف فعليا المفروض نسوي انكودينق للاعمده الجديده اللي عملناهم بعد الهندسه وكان هاض الحل الوحيد المنطقي ++ ما بزبط اسوي\n",
        "VIF وانا عامل انكودينق"
      ],
      "metadata": {
        "id": "a16c00e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "KF = KFold(n_splits = 5 , shuffle = True , random_state = 42)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"encoding\" , OneHotEncoder(handle_unknown = \"ignore\" , sparse_output = True , drop = \"first\") , low_cols) ,\n",
        "\n",
        "        # Target Encoding يُستخدم مع الأعمدة الفئوية ذات عدد القيم الكبير.\n",
        "        # يتم تحويل كل فئة إلى متوسط قيمة المتغير الهدف المرتبط بها.\n",
        "        # لتجنب تسريب الهدف (Target Leakage)، يتم تطبيق الترميز داخل\n",
        "        # الـ Cross-Validation بحيث يُحسب الترميز من بيانات التدريب فقط.\n",
        "        # معاملات min_samples_leaf و smoothing تقلل تأثير الفئات النادرة\n",
        "        # عبر تقريبها من المتوسط العام، مما يحد من الـ overfitting.\n",
        "        (\"target_encoding\" , ce.TargetEncoder(min_samples_leaf = 20 , smoothing = 50) , high_cols) ,\n",
        "        (\"Frequency\" , ce.CountEncoder(normalize = True) , Frequency_col) ,\n",
        "        (\"scaling\" , StandardScaler() , num_cols)\n",
        "                 ]\n",
        ")\n",
        "# معامل الفريكوانسي ترو ليش؟ , لانه اذا حطيتو فولز اللي رح يصير انه رح يوخذ عدد التكرارات زي ما هو في هيك بصير عندي تباين كبير ورح يصير بحاجه لسكيلينق\n",
        "#اما هيك اللي رح يعملو انه رح يحولهم لنسبة بين ال 0 وال 1\n",
        "\n"
      ],
      "metadata": {
        "id": "0e09d3e2",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.365116Z",
          "iopub.execute_input": "2025-12-26T12:00:04.365454Z",
          "iopub.status.idle": "2025-12-26T12:00:04.38267Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.365418Z",
          "shell.execute_reply": "2025-12-26T12:00:04.381655Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Numeric Columns:\" , len(num_cols))\n",
        "print(num_cols)\n",
        "\n",
        "#بعد اكثر من تجربه افضل ناتج طلعلي كن زي اللي حطيتهم بالبريبروسيس\n",
        "#best_params_for_TE(final_df , high_cols)"
      ],
      "metadata": {
        "id": "6c5d4e34",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.383942Z",
          "iopub.execute_input": "2025-12-26T12:00:04.384249Z",
          "iopub.status.idle": "2025-12-26T12:00:04.403895Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.384222Z",
          "shell.execute_reply": "2025-12-26T12:00:04.402942Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "8: Imbalanced data handling (classification)"
      ],
      "metadata": {
        "id": "cf024c3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.info()"
      ],
      "metadata": {
        "id": "ba744831",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.405051Z",
          "iopub.execute_input": "2025-12-26T12:00:04.405397Z",
          "iopub.status.idle": "2025-12-26T12:00:04.426146Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.40537Z",
          "shell.execute_reply": "2025-12-26T12:00:04.425116Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "اللي قاعد بصير هسا اني نقلت الانكوديرز لبعد مرحلة الهندسه , ليش ؟\n",
        "لانه بكل بساطه احترت كيف فعليا المفروض نسوي انكودينق للاعمده الجديده اللي عملناهم بعد الهندسه وكان هاض الحل الوحيد المنطقي ++ ما بزبط اسوي\n",
        "VIF وانا عامل انكودينق"
      ],
      "metadata": {
        "id": "921d2b17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"#الموضوع هاض عباره عن وجود عدم توازين في تصنيف البيانات , مثلا الكلاس الاول نسبته اعلى من الثاني , ف هيك الموديل بصير يعتمد عالاول ويهمل الثاني\n",
        "#ف هيك بصير الموديل فاشل باكتشاف الانماط الجديد\n",
        "\n",
        "#تجهيز بيانات التصنيف#\n",
        "\n",
        "#جبت عينات من الداتا لانه اللابتوب شلف عندي لما اشتغلت عالداتا كامله , حاولت اكبر نسبة العينات قد ما بقدر\n",
        "SAMPLE_SIZE = 1000000\n",
        "final_sample = final_df.sample(n = SAMPLE_SIZE , random_state = 42)\n",
        "\n",
        "x_c = final_sample.drop(\"reordered\", axis=1)\n",
        "y_c = final_sample[\"reordered\"]\n",
        "\n",
        "xc_train , xc_test , yc_train , yc_test = train_test_split(x_c , y_c , test_size = 0.3 , stratify = y_c , random_state = 42)\n",
        "\n",
        "#طلعلي هيك SettingWithCopyWarning\n",
        "xc_train = xc_train.copy()\n",
        "xc_test  = xc_test.copy()\n",
        "\n",
        "#هالحركه سويتها بعد ما متت وانا بحلل الكود بعد ما طلعلي التنبيه هاض\n",
        "#Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
        "#لما راجعت الانكوديرز تذكرت انه التارقيت ما بشتغل غير مع نصوص والاعمده اللي انا معطيه اياهم رقميات\n",
        "\n",
        "train_cls = preprocessor.fit_transform(xc_train , yc_train)\n",
        "test_cls = preprocessor.transform(xc_test)\n",
        "\n",
        "''''''''''''''''''''''''''''''''''''''''''''''''\n",
        "#طيب هون بالتايم اوير سبلتنق المفروض نقسم الداتا حسب التوقيت طيب ليش ؟\n",
        "#الداتا الجديده بقصد فيها الي صارت اخر شي او الطلبات الجديده او يعني الي اخر اشي عمله الزبون\n",
        "#اولا عشان التقسيم العشوائي بالداتا تبعتنا بعمللنا مشكله شو المشكله هي انو المودل لما يجي يعمل فيت للداتا رح يعمل فيت ويتعلم على داتا جدي\n",
        "#بعد مايعمل فيت على داتا ممكن تكون جديده ممكن يكون التيست عنا داتا قديمه فهيك المودل رح يكون متعلم من داتا الجديده وهيك بغش حالو\n",
        "#وهيك بغش حالو  وبجيب اكيورسي عاليه كذابه تمام فا لازم نحل هالمشكله\n",
        "#طيب لازم نعمل سامبل سايز لانو الامور هيك حتصير كثير كبيره بدونو ومع السموت هاض الداتا بتتضاعف ومابتحمل الرام\n",
        "#ولازن مانتسخدم السامبلز سايز عادي عشان مانخرب توزيع الداتا افضل يعني\n",
        "#لو استحدمت سامبلنق عادي رح نفقد كثير داتا يعني مثلا ممكن ليوز معين نفقد الاوردر تاعو رقم 3 او اورد رقم 5\n",
        "#بينما باليوزر سامبلنق انا باخذ كل الداتا لاشخاص اقل بس\n",
        "#  User Sampling\n",
        "unique_users = final_df['user_id'].unique()\n",
        "\n",
        "# هون السايز خليتو انتجر لانو مثيود الرانودوم تشويس لازمها عدد صحيح مش عشري\n",
        "new_size = int(len(unique_users) * 0.05)\n",
        "\n",
        "#  اخترت اليوزرز بشكل عشوائي بدون تكرار\n",
        "my_users = np.random.choice(unique_users, size=new_size , replace=False)\n",
        "\n",
        "#  فلترت الداتا خليت بس الأسطر اللي بتخص اليوزرز اللي اخترتهم\n",
        "final_sample = final_df[final_df['user_id'].isin(my_users)].copy()\n",
        "# هسا لازم نتاكد انو الداتا مرتبه\n",
        "\n",
        "final_sample = final_sample.sort_values(by=[\"user_id\",\"order_number\"])\n",
        "\n",
        "# هسا بعد مارتبنا مطلوب منا نعمل نقسم الداتا طيب شو في طريقه نقسمها في اكثر من طريقه لكن كلهم معقدين فا هاي ابسط اشي لحالتنا\n",
        "#الي هي انو نعمل كولوم جديده نحط فيه الداتا الجديده تمام وبنقسم على ااساسها\n",
        "#هون الهدف نعمل كولوم جديد فيه قيم صح وخطا الان القيم الصح او الترو بنحطها للتيست وقيم الفولس بنحطها للترين تمام ها\n",
        "#الان كيف نعمل هاي القصه من خلال انو بنمرر كولم الاوردر نمبر تمام وبنقارن كل اوردر لكل يوزر مع الماكس او الطلب الاخير لهاض اليوز\n",
        "#فلو كان اليوزر الطلب الي بنقارنه هو نفسه الطلب الاخير اله حيرجع ترو تمام\n",
        "#هون جربت استخدم بدون ترانسفورم لاني ماكنت اعرفها طلع عندي ايرور والايرور لانو لو خليت الميثود بدونها رح ترجعلي داتا مضغوطه لانو بجيب الزبده لكل\n",
        "#لانو بجيب الزبده لكل كولوم فالحل ترانسفورم عشان نطبق الماكس عكل نقطه داتا عندي تم ؟ تم\n",
        "\n",
        "final_sample[\"last__orders\"]= final_sample[\"order_number\"] == final_sample.groupby(\"user_id\")[\"order_number\"].transform(\"max\")\n",
        "#هون قسمنا زي ما مطلوب منا\n",
        "train_df = final_sample[final_sample['last__orders'] == False]\n",
        "test_df = final_sample[final_sample['last__orders'] == True]\n",
        "#===\n",
        "\n",
        "# هون بدنا نقسم الداتا تاعت التريت بدنا نعطي الاكس الكولمز المهمه بس ونشيل كولوم التارقيت منها\n",
        "not_for_X_columns = ['reordered', 'eval_set', 'last__orders',  'order_id',]\n",
        "X_train = train_df.drop(columns=not_for_X_columns, errors='ignore')\n",
        "y_train = train_df['reordered']\n",
        "\n",
        "#نفس الشي للتيست\n",
        "X_test = test_df.drop(columns=not_for_X_columns, errors='ignore')\n",
        "y_test = test_df['reordered']\n",
        "\n",
        "# Fit على التدريب فقط\n",
        "train_cls = preprocessor.fit_transform(X_train , y_train)\n",
        "test_cls = preprocessor.transform(X_test)\n",
        "\"\"\"\n",
        "\n",
        "target_users_count = 4000\n",
        "\n",
        "unique_users = final_df['user_id'].unique()\n",
        "\n",
        "if target_users_count > len(unique_users):\n",
        "    target_users_count = len(unique_users)\n",
        "\n",
        "np.random.seed(42)\n",
        "my_users = np.random.choice(unique_users , size=target_users_count , replace=False)\n",
        "\n",
        "final_sample = final_df[final_df['user_id'].isin(my_users)].copy()\n",
        "\n",
        "final_sample = final_sample.sort_values(by=[\"user_id\", \"order_number\"])\n",
        "final_sample[\"last__orders\"] = final_sample[\"order_number\"] == final_sample.groupby(\"user_id\")[\"order_number\"].transform(\"max\")\n",
        "\n",
        "train_df = final_sample[final_sample['last__orders'] == False]\n",
        "test_df = final_sample[final_sample['last__orders'] == True]\n",
        "\n",
        "not_for_X_columns = ['reordered' , 'eval_set' , 'last__orders' ,  'order_id' , 'add_to_cart_order' , 'uxp_total_bought' , 'uxp_reorder_ratio' , 'order_number']\n",
        "\n",
        "xc_train = train_df.drop(columns=not_for_X_columns , errors='ignore')\n",
        "yc_train = train_df['reordered']\n",
        "\n",
        "xc_test = test_df.drop(columns = not_for_X_columns , errors = 'ignore')\n",
        "yc_test = test_df['reordered']\n",
        "\n",
        "real_num_cols = [c for c in num_cols if c not in not_for_X_columns]\n",
        "real_low_cols = [c for c in low_cols if c not in not_for_X_columns]\n",
        "real_high_cols = [c for c in high_cols if c not in not_for_X_columns]\n",
        "\n",
        "#مدامني قسمت الداتا حسب الزمن فهيك عالاغلب مش رح احتاجه\n",
        "KF = KFold(n_splits = 5 , shuffle = True , random_state = 42)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"encoding\" , OneHotEncoder(handle_unknown = \"ignore\" , sparse_output = True , drop = \"first\") , real_low_cols) ,\n",
        "\n",
        "        # Target Encoding يُستخدم مع الأعمدة الفئوية ذات عدد القيم الكبير.\n",
        "        # يتم تحويل كل فئة إلى متوسط قيمة المتغير الهدف المرتبط بها.\n",
        "        # لتجنب تسريب الهدف (Target Leakage)، يتم تطبيق الترميز داخل\n",
        "        # الـ Cross-Validation بحيث يُحسب الترميز من بيانات التدريب فقط.\n",
        "        # معاملات min_samples_leaf و smoothing تقلل تأثير الفئات النادرة\n",
        "        # عبر تقريبها من المتوسط العام، مما يحد من الـ overfitting.\n",
        "        (\"target_encoding\" , ce.TargetEncoder(min_samples_leaf = 20 , smoothing = 50) , real_high_cols) ,\n",
        "        (\"Frequency\" , ce.CountEncoder(normalize = True) , Frequency_col) ,\n",
        "        (\"scaling\" , StandardScaler() , real_num_cols)\n",
        "                 ]\n",
        ")\n",
        "# معامل الفريكوانسي ترو ليش؟ , لانه اذا حطيتو فولز اللي رح يصير انه رح يوخذ عدد التكرارات زي ما هو في هيك بصير عندي تباين كبير ورح يصير بحاجه لسكيلينق\n",
        "#اما هيك اللي رح يعملو انه رح يحولهم لنسبة بين ال 0 وال 1\n",
        "\n",
        "\n",
        "\n",
        "train_cls = preprocessor.fit_transform(xc_train , yc_train)\n",
        "test_cls = preprocessor.transform(xc_test)"
      ],
      "metadata": {
        "id": "2a4f4a9a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:04.427358Z",
          "iopub.execute_input": "2025-12-26T12:00:04.427676Z",
          "iopub.status.idle": "2025-12-26T12:00:14.562188Z",
          "shell.execute_reply.started": "2025-12-26T12:00:04.427647Z",
          "shell.execute_reply": "2025-12-26T12:00:14.561255Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "available_users = xc_train[\"user_id\"].unique()\n",
        "n_users = len(available_users)\n",
        "n_users"
      ],
      "metadata": {
        "id": "e3c06d70",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:14.563209Z",
          "iopub.execute_input": "2025-12-26T12:00:14.563473Z",
          "iopub.status.idle": "2025-12-26T12:00:14.649554Z",
          "shell.execute_reply.started": "2025-12-26T12:00:14.563449Z",
          "shell.execute_reply": "2025-12-26T12:00:14.648635Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#اصريت اتأكد انه الترانسفورم تطبق\n",
        "print(train_cls.shape)\n",
        "print(xc_train.shape)\n",
        "print()\n",
        "preprocessor.get_feature_names_out()"
      ],
      "metadata": {
        "id": "11140884",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:14.650583Z",
          "iopub.execute_input": "2025-12-26T12:00:14.650862Z",
          "iopub.status.idle": "2025-12-26T12:00:14.658989Z",
          "shell.execute_reply.started": "2025-12-26T12:00:14.650836Z",
          "shell.execute_reply": "2025-12-26T12:00:14.658219Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(yc_train.value_counts(normalize=True))\n",
        "\n",
        "plt.figure(figsize=(6 , 4))\n",
        "sns.countplot(x=yc_train)\n",
        "plt.title(\"Class Distribution in Training Set\")\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n",
        "\n",
        "#هيك بين عندي انه في تفاوت بنسب الكلاسين اللي عندي , الفرق ما بأثر كثير بس لازم اعمل موازنه لانه الدكتور طلب"
      ],
      "metadata": {
        "id": "eaa1a40c",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:14.660035Z",
          "iopub.execute_input": "2025-12-26T12:00:14.660536Z",
          "iopub.status.idle": "2025-12-26T12:00:15.557276Z",
          "shell.execute_reply.started": "2025-12-26T12:00:14.660509Z",
          "shell.execute_reply": "2025-12-26T12:00:15.556457Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''smote = SMOTE(random_state=42)\n",
        "smote_xtrain, smote_ytrain = smote.fit_resample(train_cls, yc_train)      #بتعمل KNN\n",
        "#اللي بصير هون انه السموت رح تزيد قيم الكلاس القليل بقيم ثناعيه او وهميه عشان التوازن\n",
        "print(smote_ytrain.value_counts())\n",
        "\n",
        "print(\"----------------------------------------------------------------\")\n",
        "# # '''\n",
        "# rus = RandomUnderSampler(random_state = 42)\n",
        "#   under_xtrain , under_ytrain = rus.fit_resample(train_cls , yc_train)\n",
        "#   #هاي بتحذف من الكلاس الكبير بطريقه يصير قريب للكلاس الاقل , فيها مشكله انه ممكن تخسر بيانات مهمه من وراها واصلا هيك هيك الدقه فيها مش احسن اشي ف ما رح نستخدمها\n",
        "#   print(under_ytrain.value_counts())"
      ],
      "metadata": {
        "id": "fe25caa3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:15.559156Z",
          "iopub.execute_input": "2025-12-26T12:00:15.559477Z",
          "iopub.status.idle": "2025-12-26T12:00:15.565387Z",
          "shell.execute_reply.started": "2025-12-26T12:00:15.559449Z",
          "shell.execute_reply": "2025-12-26T12:00:15.564524Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_original = RandomForestClassifier(n_estimators = 50 , max_depth = 20 , class_weight = \"balanced\")\n",
        "#class_weight = 'balanced' هاي بتعطي اهميه اكبر للكلاس الاقل , يعني بتعاقب الموديل لما يهمله ف مجازيا بزيد وزنه , تعتبر بديل لكلشي عملناه تحت\n",
        "#بدونها رح يكون في تحييز للكلاس اللي حجمه اكبر , وليش ؟ لانه الموديل بفهم انه هاض الكلاس لانه اكبر معناها هاض مهم والثاني لا\n",
        "model_original.fit(train_cls , yc_train)\n",
        "\n",
        "pred_O = model_original.predict(test_cls)\n",
        "print(classification_report(yc_test , pred_O))\n",
        "print(model_original.score(test_cls , yc_test))\n",
        "\n",
        "print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# model_smote = RandomForestClassifier(n_estimators = 50 , max_depth = 20)\n",
        "# model_smote.fit(smote_xtrain , smote_ytrain)\n",
        "\n",
        "# pred_S = model_smote.predict(test_cls)\n",
        "# print(classification_report(yc_test , pred_S))\n",
        "# print(model_smote.score(test_cls , yc_test))\n",
        "\n",
        "# #السكور زاد بنسبه خفيفه , استدعاء الفئه اللي كانت اقل تحسن , الدقه قلت بنسبة خفيفه والسبب انه بطل يعتمد على كلاس واحد صار يعتمد على ثنين بالتصنيف ف نسبة الدقه اقل هون\n",
        "\n",
        "\n",
        "# print(\"----------------------------------------------------------------\")\n",
        "\n",
        "# model_under = RandomForestClassifier(n_estimators = 50 , max_depth = 20 , random_state = 42)\n",
        "# model_under.fit(under_xtrain , under_ytrain)\n",
        "\n",
        "# pred_U = model_under.predict(test_cls)\n",
        "# print(classification_report(yc_test , pred_U))\n",
        "# print(model_under.score(test_cls , yc_test))"
      ],
      "metadata": {
        "id": "cd7dd078",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:00:15.566491Z",
          "iopub.execute_input": "2025-12-26T12:00:15.567112Z",
          "iopub.status.idle": "2025-12-26T12:01:13.017774Z",
          "shell.execute_reply.started": "2025-12-26T12:00:15.567085Z",
          "shell.execute_reply": "2025-12-26T12:01:13.016828Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
        "\n",
        "models_list = [\n",
        "    (model_original, \"Original (Class Weights)\"),\n",
        "    (model_smote, \"SMOTE\"),\n",
        "    (model_under, \"UnderSampling\")\n",
        "]\n",
        "\n",
        "for i, (model, title) in enumerate(models_list):\n",
        "    disp = ConfusionMatrixDisplay.from_estimator(\n",
        "        model,\n",
        "        test_cls,\n",
        "        yc_test,\n",
        "        display_labels=['Not Reordered', 'Reordered'],\n",
        "        cmap=plt.cm.Blues,\n",
        "        normalize='true',\n",
        "        ax=axes[i]\n",
        "    )\n",
        "    axes[i].set_title(title)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''\n",
        "#اول مره جربت اشغل هذول عالبيانات قبل التوزيع حسب الزمن , كان تقسيم عشوائي , وطلع معي انع الالفضل سموت , بس بعد التقسيم حسب الزمن رح نعتمد الداتا الاصليه\n",
        "## رجعت جربت بيانات اكبر وطلع معي السموت اعلى بنسبه بسيييييييطه وعشان هيك مش رح اهتم بالنسبه هاي ورح اعتمد الداتا الاصليه لانها ما بتوخذ وقت عكس السموت"
      ],
      "metadata": {
        "id": "1d321154",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.018901Z",
          "iopub.execute_input": "2025-12-26T12:01:13.019199Z",
          "iopub.status.idle": "2025-12-26T12:01:13.025543Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.019141Z",
          "shell.execute_reply": "2025-12-26T12:01:13.024696Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "رح نعتمد هذول بالتدريب train_cls , yc_train\n",
        "\n",
        "وهذول بالاختبار test_cls , yc_test"
      ],
      "metadata": {
        "id": "406aeeb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task A"
      ],
      "metadata": {
        "id": "02076bca"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree classifier\n"
      ],
      "metadata": {
        "id": "8dc424d8-26a7-4ede-8153-94ea9afa86ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# np.random.seed(42)\n",
        "# tuning_users_ids = np.random.choice(xc_train['user_id'].unique(), size=2500, replace=False)\n",
        "# # سحب الداتا الخاصة بهؤلاء اليوزرز\n",
        "# DT_x_small = xc_train[xc_train['user_id'].isin(tuning_users_ids)].copy().sort_values(by=['user_id'])\n",
        "# DT_y_small = yc_train.loc[DT_x_small.index]\n",
        "# print(f\"Sample Size for Tuning: {DT_x_small.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.026771Z",
          "iopub.execute_input": "2025-12-26T12:01:13.027198Z",
          "iopub.status.idle": "2025-12-26T12:01:13.04691Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.027138Z",
          "shell.execute_reply": "2025-12-26T12:01:13.045734Z"
        },
        "id": "16330e01-9d9a-4a5d-b498-08e9e757d562"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\n2️⃣ Setting up Pipeline & GridSearch...\")\n",
        "\n",
        "# # 1. دمج المعالج (preprocessor) مع المودل (DecisionTree) في خطوة واحدة\n",
        "# DT_pipeline = make_pipeline(\n",
        "#     preprocessor,\n",
        "#     DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
        "# )\n",
        "\n",
        "# # 2. تجهيز قائمة الاحتمالات اللي بدنا نجربها\n",
        "# # ملاحظة: لازم نكتب اسم المودل (decisiontreeclassifier) بعدين شرطتين (__) قبل اسم الباراميتر\n",
        "# DT_param_grid = {\n",
        "#     \"decisiontreeclassifier__max_depth\": [10, 15, 20, None],      # جرب هدول الأعماق\n",
        "#     \"decisiontreeclassifier__min_samples_leaf\": [20, 50, 100],    # جرب هدول الأعداد للأوراق\n",
        "#     \"decisiontreeclassifier__criterion\": [\"gini\", \"entropy\"]      # جرب المعادلتين\n",
        "# }\n",
        "\n",
        "# # 3. إعداد أداة البحث (GridSearchCV)\n",
        "# DT_grid_search = GridSearchCV(\n",
        "#     estimator = DT_pipeline,   # البايبلاين اللي عملناه\n",
        "#     param_grid = DT_param_grid,# الاحتمالات اللي فوق\n",
        "#     cv = 3,                    # قسم العينة لـ 3 أجزاء للتأكد (Cross Validation)\n",
        "#     scoring = \"f1\",            # أهم مقياس عنا هو F1 للكلاس 1\n",
        "#     n_jobs = -1,               # شغل كل أنوية المعالج عشان السرعة\n",
        "#     verbose = 1                # طلعلي كلام عالشاشة وأنت بتشتغل\n",
        "# )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.048348Z",
          "iopub.execute_input": "2025-12-26T12:01:13.04872Z",
          "iopub.status.idle": "2025-12-26T12:01:13.063694Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.048685Z",
          "shell.execute_reply": "2025-12-26T12:01:13.062644Z"
        },
        "id": "ce3cb5fb-8f93-495a-a703-048e0126033a"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Running GridSearchCV on Small Sample...\")\n",
        "\n",
        "# # تدريب البحث على العينة الصغيرة فقط للسرعة\n",
        "# DT_grid_search.fit(DT_x_small, DT_y_small)\n",
        "\n",
        "# print(\"\\n Tuning Done\")\n",
        "# print(\"Best Score (F1):\", DT_grid_search.best_score_)\n",
        "# print(\"Best Parameters:\", DT_grid_search.best_params_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.064916Z",
          "iopub.execute_input": "2025-12-26T12:01:13.06527Z",
          "iopub.status.idle": "2025-12-26T12:01:13.084645Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.065231Z",
          "shell.execute_reply": "2025-12-26T12:01:13.083599Z"
        },
        "id": "63d18dab-e823-4de2-97a0-48adb96ea21f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"\\n3️⃣ Training Final Decision Tree Model on FULL Data...\")\n",
        "\n",
        "# # 1. استخراج أفضل القيم الفائزة\n",
        "# best_params = DT_grid_search.best_params_\n",
        "\n",
        "# # 2. بناء المودل النهائي بهذه القيم\n",
        "# final_DT_pipeline = make_pipeline(\n",
        "#     preprocessor,\n",
        "#     DecisionTreeClassifier(\n",
        "#         criterion = best_params['decisiontreeclassifier__criterion'],\n",
        "#         max_depth = best_params['decisiontreeclassifier__max_depth'],\n",
        "#         min_samples_leaf = best_params['decisiontreeclassifier__min_samples_leaf'],\n",
        "#         class_weight = 'balanced',\n",
        "#         random_state = 42\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# # 3. التدريب على الداتا الكاملة (xc_train)\n",
        "# # لاحظ: استخدمنا xc_train لأن البايبلاين يبدأ بالمعالجة من الصفر\n",
        "# final_DT_pipeline.fit(xc_train, yc_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.085773Z",
          "iopub.execute_input": "2025-12-26T12:01:13.086088Z",
          "iopub.status.idle": "2025-12-26T12:01:13.10135Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.08606Z",
          "shell.execute_reply": "2025-12-26T12:01:13.10022Z"
        },
        "id": "08f74a93-e279-4b3a-8b84-7ae6b5e3c7b9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Predicting on Test Set...\")\n",
        "\n",
        "# # التوقع باستخدام المودل النهائي\n",
        "# y_pred_dt = final_DT_pipeline.predict(xc_test)\n",
        "\n",
        "# print(\"\\n--- Final Decision Tree Report ---\")\n",
        "# print(classification_report(yc_test, y_pred_dt))\n",
        "\n",
        "# print(f\"Decision Tree Accuracy: {final_DT_pipeline.score(xc_test, yc_test)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.10256Z",
          "iopub.execute_input": "2025-12-26T12:01:13.102858Z",
          "iopub.status.idle": "2025-12-26T12:01:13.122239Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.102829Z",
          "shell.execute_reply": "2025-12-26T12:01:13.12128Z"
        },
        "id": "ea267821-3c2c-44a2-8339-a75dab16001c"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "1- KNN"
      ],
      "metadata": {
        "id": "36a7698b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#هون رح اعتمد الاندر , لانه الموديل هون بصنف حسب الاقرب وبحالتي هاي ما بزبط يكون الداتا فيها عدم توازن , وما بقدر استخدم\n",
        "# class_weight = 'balanced'\n",
        "\n",
        "# '''np.random.seed(42)\n",
        "\n",
        "# small_users = np.random.choice(xc_train['user_id'].unique(), size=3000, replace=False)\n",
        "\n",
        "# xtrain_tune = xc_train[xc_train['user_id'].isin(small_users)].copy()\n",
        "# ytrain_tune = yc_train.loc[xtrain_tune.index].copy()\n",
        "\n",
        "# xtest_tune = xc_test[xc_test['user_id'].isin(small_users)].copy()\n",
        "# ytest_tune = yc_test.loc[xtest_tune.index].copy()'''\n",
        "\n",
        "\n",
        "\n",
        "# np.random.seed(42)\n",
        "# tuning_x = xc_train.copy()\n",
        "# tuning_y = yc_train.copy()\n",
        "\n",
        "# t = TimeSeriesSplit(n_splits = 3)\n",
        "\n",
        "# '''trainK = []\n",
        "# testK = []\n",
        "# k_values = range(1 , 22 , 2)\n",
        "\n",
        "# for n in k_values:\n",
        "#     tempK = KNeighborsClassifier(n_neighbors = n , n_jobs = -1)\n",
        "#     Knn_model = tempK.fit(under_xtrain , under_ytrain)\n",
        "#     trainK.append(tempK.score(x_trainS , y_trainS))\n",
        "#     testK.append(tempK.score(x_testS , y_testS))\n",
        "\n",
        "# print(testK)\n",
        "\n",
        "# plt.plot(k_values , trainK , label = \"Traink\")\n",
        "# plt.plot(k_values , testK , label = \"Testk\")\n",
        "# plt.ylabel(\"Accuracy\")\n",
        "# plt.xlabel(\"n_neighbors\")\n",
        "# plt.legend()'''"
      ],
      "metadata": {
        "id": "16f911c4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.123436Z",
          "iopub.execute_input": "2025-12-26T12:01:13.124214Z",
          "iopub.status.idle": "2025-12-26T12:01:13.13762Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.124149Z",
          "shell.execute_reply": "2025-12-26T12:01:13.136728Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''FAST_TUNING_USERS = 1000\n",
        "\n",
        "np.random.seed(42)\n",
        "# بنختار عينة جديدة صغيرة من العينة الأصلية الكبيرة\n",
        "KNNsmall_users = np.random.choice(xtrain_tune['user_id'].unique(), size=800, replace=False)\n",
        "\n",
        "# تصفية الداتا\n",
        "knn_x_small = xtrain_tune[xtrain_tune['user_id'].isin(small_users)].copy()\n",
        "knn_y_small = ytrain_tune[xtrain_tune['user_id'].isin(small_users)]\n",
        "\n",
        "KNN_pipline = make_pipeline(\n",
        "    preprocessor ,\n",
        "    KNeighborsClassifier()\n",
        ")\n",
        "\n",
        "\n",
        "t = TimeSeriesSplit(n_splits = 3)\n",
        "\n",
        "param_grid = {\n",
        "    \"kneighborsclassifier__n_neighbors\": [7 , 10 , 20 , 25 , 30] ,\n",
        "    \"kneighborsclassifier__weights\" : ['distance' , 'uniform']\n",
        "}\n",
        "\n",
        "KNN_grid_search = GridSearchCV(\n",
        "    estimator = KNN_pipline ,\n",
        "    param_grid = param_grid ,\n",
        "    cv = t ,\n",
        "    scoring = 'f1' ,\n",
        "    n_jobs = -1 ,\n",
        "    verbose=3\n",
        ")\n",
        "\n",
        "print(\"Done.....\")\n",
        "\n",
        "KNN_grid_search.fit(knn_x_small , knn_y_small)\n",
        "\n",
        "print(\"Best CV score:\" , KNN_grid_search.best_score_)\n",
        "print(\"Best params:\" , KNN_grid_search.best_params_)'''\n",
        "\n",
        "\n",
        "'''KNNsmall_users = np.random.choice(tuning_x['user_id'].unique() , size = 2000 , replace = False)\n",
        "\n",
        "knn_x_small = tuning_x[tuning_x['user_id'].isin(KNNsmall_users)].copy()\n",
        "knn_y_small = tuning_y[tuning_x['user_id'].isin(KNNsmall_users)]\n",
        "\n",
        "\n",
        "\n",
        "KNN_pipline = make_pipeline(\n",
        "    preprocessor ,\n",
        "    KNeighborsClassifier()\n",
        ")\n",
        "\n",
        "KNNparam_grid = {\n",
        "    \"kneighborsclassifier__n_neighbors\": [7 , 10 , 20 , 25 , 30] ,\n",
        "    \"kneighborsclassifier__weights\" : ['distance' , 'uniform']\n",
        "}\n",
        "\n",
        "KNN_grid_search = GridSearchCV(\n",
        "    estimator = KNN_pipline ,\n",
        "    param_grid = KNNparam_grid ,\n",
        "    cv = t ,\n",
        "    scoring = \"f1\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "KNN_grid_search.fit(knn_x_small , knn_y_small)\n",
        "\n",
        "print(\"\\nBest Score:\", KNN_grid_search.best_score_)\n",
        "print(\"Best Parameters:\", KNN_grid_search.best_params_)'''\n"
      ],
      "metadata": {
        "id": "0e97d996",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.138673Z",
          "iopub.execute_input": "2025-12-26T12:01:13.139256Z",
          "iopub.status.idle": "2025-12-26T12:01:13.160161Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.139219Z",
          "shell.execute_reply": "2025-12-26T12:01:13.159269Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''best_w = KNN_grid_search.best_params_['kneighborsclassifier__weights']\n",
        "best_k = KNN_grid_search.best_params_['kneighborsclassifier__n_neighbors']\n",
        "\n",
        "finalKNN_pip = make_pipeline(\n",
        "        preprocessor ,\n",
        "        KNeighborsClassifier(n_neighbors = best_k , weights = best_w , n_jobs = -1)\n",
        ")\n",
        "\n",
        "finalKNN_pip.fit(xc_train, yc_train)\n",
        "\n",
        "print(\"Final Accuracy Score:\")\n",
        "print(finalKNN_pip.score(xc_test, yc_test))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "y_pred = finalKNN_pip.predict(xc_test)\n",
        "print(classification_report(yc_test, y_pred))'''\n"
      ],
      "metadata": {
        "id": "c4953978",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.161309Z",
          "iopub.execute_input": "2025-12-26T12:01:13.16162Z",
          "iopub.status.idle": "2025-12-26T12:01:13.18188Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.161581Z",
          "shell.execute_reply": "2025-12-26T12:01:13.181007Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#بعد تطبيق تقسيم زمني واقعي ومعالجة عدم التوازن، انخفضت الدقة من قيم مرتفعة غير واقعية إلى ~0.7،\n",
        "#إلا أن قدرة النموذج على اكتشاف المنتجات المعاد طلبها (Recall) تحسّنت بشكل واضح،\n",
        "#مما يجعل النموذج أكثر ملاءمة للاستخدام الحقيقي."
      ],
      "metadata": {
        "id": "816c7928",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.183028Z",
          "iopub.execute_input": "2025-12-26T12:01:13.183335Z",
          "iopub.status.idle": "2025-12-26T12:01:13.198845Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.183309Z",
          "shell.execute_reply": "2025-12-26T12:01:13.198013Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-Logistic Regression"
      ],
      "metadata": {
        "id": "f866ab53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tuning_users = np.random.choice(tuning_x[\"user_id\"].unique(), size=2500, replace=False) # رجعناها 2000\n",
        "\n",
        "# # تجهيز عينة التونينق\n",
        "# LoR_x_small = tuning_x[tuning_x['user_id'].isin(tuning_users)].copy().sort_values(by=['user_id'])\n",
        "# LoR_y_small = tuning_y.loc[LoR_x_small.index]\n",
        "\n",
        "# LoR_pipline = make_pipeline(\n",
        "#     preprocessor ,\n",
        "#     LogisticRegression(solver = 'liblinear' , class_weight = 'balanced' , random_state = 42)\n",
        "# )\n",
        "\n",
        "# LoRparam_grid = {\n",
        "#     \"logisticregression__C\": [0.001 , 0.01 , 0.1 , 1 , 10] ,\n",
        "#     \"logisticregression__penalty\": ['l1' , 'l2']\n",
        "# }\n",
        "\n",
        "# LoR_grid_search = GridSearchCV(\n",
        "#     estimator = LoR_pipline ,\n",
        "#     param_grid = LoRparam_grid ,\n",
        "#     cv = t ,\n",
        "#     scoring = \"f1\" ,\n",
        "#     n_jobs = -1\n",
        "# )\n",
        "\n",
        "# LoR_grid_search.fit(LoR_x_small , LoR_y_small)\n",
        "\n",
        "# print(\"\\nBest Score:\", LoR_grid_search.best_score_)\n",
        "# print(\"Best Parameters:\", LoR_grid_search.best_params_)\n",
        "\n",
        "# \"\"\"Best Score: 0.7038598274542919\n",
        "# Best Parameters: {'logisticregression__C': 0.001, 'logisticregression__penalty': 'l2'}\"\"\""
      ],
      "metadata": {
        "id": "068f5ca7",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.20011Z",
          "iopub.execute_input": "2025-12-26T12:01:13.200509Z",
          "iopub.status.idle": "2025-12-26T12:01:13.214683Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.200476Z",
          "shell.execute_reply": "2025-12-26T12:01:13.213419Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# final_LoR_pipeline = make_pipeline(\n",
        "#     preprocessor,\n",
        "#     LogisticRegression(\n",
        "#         solver='liblinear',\n",
        "#         C=0.001,\n",
        "#         penalty='l2',\n",
        "#         class_weight='balanced',\n",
        "#         random_state=42\n",
        "#     )\n",
        "# )\n",
        "\n",
        "# print(\"Training Final Logistic Model...\")\n",
        "# final_LoR_pipeline.fit(xc_train, yc_train)\n",
        "\n",
        "# print(\"Predicting on Test Set...\")\n",
        "# y_pred_log = final_LoR_pipeline.predict(xc_test)\n",
        "\n",
        "# print(\"\\n--- Final Logistic Regression Report ---\")\n",
        "# print(classification_report(yc_test, y_pred_log))\n",
        "\n",
        "# print(f\"Logistic Accuracy: {final_LoR_pipeline.score(xc_test, yc_test):.4f}\")"
      ],
      "metadata": {
        "id": "cacdee95",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.22253Z",
          "iopub.execute_input": "2025-12-26T12:01:13.223144Z",
          "iopub.status.idle": "2025-12-26T12:01:13.230072Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.223111Z",
          "shell.execute_reply": "2025-12-26T12:01:13.229262Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "3- Random Forest"
      ],
      "metadata": {
        "id": "bdd5a355"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RF = RandomForestClassifier(n_estimators = 150 , max_depth = 20 , class_weight = \"balanced\" , n_jobs = -1 , random_state = 42)\n",
        "# RF.fit(train_cls , yc_train)\n",
        "\n",
        "# pred_R = RF.predict(test_cls)\n",
        "# print(classification_report(yc_test , pred_R))\n",
        "\n",
        "# #---------------------------------------------------------------------#\n",
        "# RF_score = RF.score(test_cls , yc_test)\n",
        "# #---------------------------------------------------------------------#\n",
        "\n",
        "# print(RF_score)\n",
        "# print(RF.score(train_cls , yc_train))\n",
        "# #بخصوص انا التدريب اقل من الاختبار ف هاي مش مشكله ترا , هي اصلا بتصير لانه في عدم توازن بالبيانات ولانه بيانات التدريب مبعثره ومش مرتبه\n",
        "# #على عكس بيانات الاختبار اللي بس بتحتوي على نوع واحد من البيانات"
      ],
      "metadata": {
        "id": "bd8469f0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.231104Z",
          "iopub.execute_input": "2025-12-26T12:01:13.231467Z",
          "iopub.status.idle": "2025-12-26T12:01:13.250047Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.231429Z",
          "shell.execute_reply": "2025-12-26T12:01:13.249094Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_names = preprocessor.get_feature_names_out()\n",
        "\n",
        "# coefs = pd.DataFrame(LoR.coef_[0] , index=feature_names , columns = ['Coefficient']).sort_values(by = 'Coefficient' , ascending = False)\n",
        "\n",
        "# print(\"\\ntop 5 positive ffeatures (factors driving reorder)\")\n",
        "# print(coefs.head(5))\n",
        "\n",
        "# print(\"\\ntop 5 negative features (factors hindring reorder)\")\n",
        "# print(coefs.tail(5))\n",
        "\n",
        "# plt.figure(figsize = (10 , 6))\n",
        "\n",
        "# top_bottom = pd.concat([coefs.head(10) , coefs.tail(10)])\n",
        "# top_bottom['Coefficient'].plot(kind = 'barh')\n",
        "# plt.title('Logistic Regression Feature Importance')\n",
        "# plt.xlabel('Impact (Coefficient)')\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "#الرسم بوضح شو اكثر الاعمده اللي أثرو عالموديل بشكل ايجابي او سلبي"
      ],
      "metadata": {
        "id": "a5e35bc1",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.251413Z",
          "iopub.execute_input": "2025-12-26T12:01:13.25211Z",
          "iopub.status.idle": "2025-12-26T12:01:13.265684Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.252082Z",
          "shell.execute_reply": "2025-12-26T12:01:13.26481Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task B\n"
      ],
      "metadata": {
        "id": "0de8e7b2-24a2-4ee8-94d6-bc14509b7ba7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_df = final_df[final_df['order_number'] > 1].copy()\n",
        "orders_level = (\n",
        "    cleaned_df\n",
        "    .sort_values([\"user_id\", \"order_number\"])      # مهم قبل drop_duplicates [web:116]\n",
        "    .drop_duplicates(\"order_id\", keep=\"last\")      # أي صف يمثل نفس الطلب [web:116]\n",
        "    .copy()\n",
        ")\n",
        "\n",
        "\n",
        "target_users_count = 15000\n",
        "unique_users = orders_level[\"user_id\"].unique()\n",
        "\n",
        "if target_users_count > len(unique_users):\n",
        "    target_users_count = len(unique_users)\n",
        "\n",
        "np.random.seed(42)\n",
        "my_users = np.random.choice(unique_users, size=target_users_count, replace=False)\n",
        "\n",
        "final_sample = orders_level[orders_level[\"user_id\"].isin(my_users)].copy()\n",
        "final_sample = final_sample.sort_values(by=[\"user_id\", \"order_number\"])\n",
        "\n",
        "\n",
        "final_sample[\"last__orders\"] = (\n",
        "    final_sample[\"order_number\"]\n",
        "    == final_sample.groupby(\"user_id\")[\"order_number\"].transform(\"max\")\n",
        ")\n",
        "\n",
        "train_df = final_sample[final_sample[\"last__orders\"] == False].copy()\n",
        "test_df  = final_sample[final_sample[\"last__orders\"] == True].copy()\n",
        "\n",
        "y_col = \"days_since_prior_order\"\n",
        "#احتياط المفروض\n",
        "train_df = train_df.dropna(subset=[y_col])\n",
        "test_df = test_df.dropna(subset=[y_col])\n",
        "\n",
        "not_for_X_columns = [\n",
        "    \"eval_set\", \"last__orders\", \"order_id\",\n",
        "    \"reordered\", \"add_to_cart_order\",\n",
        "    \"order_number\", y_col\n",
        "]\n",
        "\n",
        "xr_train = train_df.drop(columns=not_for_X_columns + [\"user_id\"], errors=\"ignore\")\n",
        "yr_train = train_df[y_col].astype(\"float32\")\n",
        "\n",
        "xr_test  = test_df.drop(columns=not_for_X_columns + [\"user_id\"], errors=\"ignore\")\n",
        "yr_test  = test_df[y_col].astype(\"float32\")\n",
        "\n",
        "\n",
        "\n",
        "real_num_col_reg = xr_train.select_dtypes(include=[\"int32\", \"float32\", \"float64\"]).columns.tolist()\n",
        "\n",
        "real_num_col_reg = [c for c in real_num_col_reg if c not in id_cols]\n",
        "\n",
        "real_low_col_reg  = [c for c in low_cols  if c in xr_train.columns]\n",
        "real_high_col_reg = [c for c in high_cols if c in xr_train.columns]\n",
        "real_freq_col_reg = [c for c in Frequency_col if c in xr_train.columns]\n",
        "\n",
        "\n",
        "\n",
        "preprocessor_reg = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"encoding\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, drop=\"first\"), real_low_col_reg),\n",
        "        (\"target_encoding\", ce.TargetEncoder(min_samples_leaf=20, smoothing=50), real_high_col_reg),\n",
        "        (\"frequency\", ce.CountEncoder(normalize=True), real_freq_col_reg),\n",
        "        (\"scaling\", StandardScaler(), real_num_col_reg),\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "train_reg = preprocessor_reg.fit_transform(xr_train, yr_train)\n",
        "test_reg  = preprocessor_reg.transform(xr_test)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:13.266704Z",
          "iopub.execute_input": "2025-12-26T12:01:13.267428Z",
          "iopub.status.idle": "2025-12-26T12:01:52.945912Z",
          "shell.execute_reply.started": "2025-12-26T12:01:13.267384Z",
          "shell.execute_reply": "2025-12-26T12:01:52.944907Z"
        },
        "id": "3948fde4-5268-4121-8152-1c024dd0a6ae"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"xr_train shape (Raw): {xr_train.shape}\")\n",
        "print(f\"train_reg shape (Processed): {train_reg.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:01:52.947089Z",
          "iopub.execute_input": "2025-12-26T12:01:52.94739Z",
          "iopub.status.idle": "2025-12-26T12:01:52.952636Z",
          "shell.execute_reply.started": "2025-12-26T12:01:52.947365Z",
          "shell.execute_reply": "2025-12-26T12:01:52.951615Z"
        },
        "id": "0069b058-ee29-4ee5-a023-15ec51526b74"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-KNN"
      ],
      "metadata": {
        "id": "fbc07bbe-9466-4490-b50f-c559dd41e77d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tuning_xr = xr_train.copy()\n",
        "tuning_yr = yr_train.copy()\n",
        "GF = GroupKFold(n_splits=5)\n",
        "\n",
        "tuning_groups = train_df[\"user_id\"].copy()\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:13:46.076162Z",
          "iopub.execute_input": "2025-12-26T12:13:46.076542Z",
          "iopub.status.idle": "2025-12-26T12:13:46.140125Z",
          "shell.execute_reply.started": "2025-12-26T12:13:46.076513Z",
          "shell.execute_reply": "2025-12-26T12:13:46.139142Z"
        },
        "id": "eab34e10-a0e6-4836-a7e9-97cea6b21051"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def model_score(model , xr_train , yr_train , xr_test , yr_test):\n",
        "    model.fit(xr_train , yr_train)\n",
        "    y_pred = model.predict(xr_test)\n",
        "\n",
        "    mae = mean_absolute_error(yr_test , y_pred)\n",
        "    print(f\"MAE:  {mae}\")\n",
        "\n",
        "    rmse = np.sqrt(mean_squared_error(yr_test , y_pred))\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "\n",
        "    r2 = r2_score(yr_test , y_pred)\n",
        "    print(f\"R2:   {r2}\")\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:13:49.655624Z",
          "iopub.execute_input": "2025-12-26T12:13:49.656006Z",
          "iopub.status.idle": "2025-12-26T12:13:49.661593Z",
          "shell.execute_reply.started": "2025-12-26T12:13:49.655975Z",
          "shell.execute_reply": "2025-12-26T12:13:49.660772Z"
        },
        "id": "c2795033-7882-4455-ae12-345811789079"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "KNNRsmall_users = np.random.choice(tuning_groups.unique(), size=5000, replace=False)\n",
        "\n",
        "mask = tuning_groups.isin(KNNRsmall_users)\n",
        "\n",
        "KNNR_x_small = tuning_xr.loc[mask].copy()\n",
        "KNNR_y_small = tuning_yr.loc[mask].copy()\n",
        "KNNR_groups_small = tuning_groups.loc[mask].copy()\n",
        "\n",
        "KNNR_pipline = make_pipeline(\n",
        "    preprocessor_reg ,\n",
        "    KNeighborsRegressor()\n",
        ")\n",
        " #  [7 , 10 , 20 , 25 , 30] هون اول اشي عملنا اخترنا\n",
        "#تمام بما انو المودل اختار 30 هاض بيعني انو لسا في مجال نضيف عدد اكبر من النيبرز فا رح نعدلها ل [30, 50, 70, 100]\n",
        "KNNRparan_grid = {\n",
        "    \"kneighborsregressor__n_neighbors\": [30, 50, 70, 100] ,\n",
        "    \"kneighborsregressor__weights\" : ['distance' , 'uniform']\n",
        "}\n",
        "\n",
        "KNNR_grid_search = GridSearchCV(\n",
        "    estimator = KNNR_pipline ,\n",
        "    param_grid = KNNRparan_grid ,\n",
        "    cv = GF ,\n",
        "    scoring = \"r2\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "\n",
        "KNNR_grid_search.fit(KNNR_x_small , KNNR_y_small , groups = KNNR_groups_small)\n",
        "\n",
        "print(\"\\nBest Score:\" , KNNR_grid_search.best_score_)\n",
        "print(\"Best Parameters:\" , KNNR_grid_search.best_params_)\n",
        "#النتائج هاي قبل تزبيط السبلت\n",
        "#\"\"\"Best Score: -8.939542770385742        neg_root_mean_squared_error\n",
        "#Best Parameters: {'kneighborsregressor__n_neighbors': 30, 'kneighborsregressor__weights': 'uniform'}\"\"\"\n",
        "#=============================================\n",
        "#النتائج هاي بعد تزبيط السبلت وعدد الجيران\n",
        "#Best Score: 0.19590063095092775\n",
        "#Best Parameters: {'kneighborsregressor__n_neighbors': 100, 'kneighborsregressor__weights': 'uniform'}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:16:53.457515Z",
          "iopub.execute_input": "2025-12-26T12:16:53.45788Z",
          "iopub.status.idle": "2025-12-26T12:18:28.552799Z",
          "shell.execute_reply.started": "2025-12-26T12:16:53.45785Z",
          "shell.execute_reply": "2025-12-26T12:18:28.551858Z"
        },
        "id": "96ae1cbd-480e-4ac2-ae1b-7dae4d3cad4d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "best_Rk = KNNR_grid_search.best_params_[\"kneighborsregressor__n_neighbors\"]\n",
        "\n",
        "best_Rw = KNNR_grid_search.best_params_[\"kneighborsregressor__weights\"]\n",
        "\n",
        "final_KNNR_pip = make_pipeline(\n",
        "    preprocessor_reg ,\n",
        "    KNeighborsRegressor(n_neighbors = best_Rk , weights = best_Rw , n_jobs = -1)\n",
        ")\n",
        "\n",
        "model_score(final_KNNR_pip , xr_train , yr_train , xr_test , yr_test)\n",
        "#قبل التعديل على السبلت وعدد الجيران هيك كانت النتائج\n",
        "#MAE:  5.356390476226807\n",
        "#RMSE: 7.753037626488352\n",
        "#R2:   0.3814122676849365\n",
        "\n",
        "#==============================\n",
        "#بعد التعديل\n",
        "#MAE:  4.928064823150635\n",
        "# RMSE: 6.896374702453613\n",
        "# R2:   0.5105602741241455\n",
        "#شوف فرق ال ار 2 بعد التعديل مش بطال على كي ان ان على داتا زي هيك"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:25:45.986558Z",
          "iopub.execute_input": "2025-12-26T12:25:45.986877Z",
          "iopub.status.idle": "2025-12-26T12:26:09.726975Z",
          "shell.execute_reply.started": "2025-12-26T12:25:45.986854Z",
          "shell.execute_reply": "2025-12-26T12:26:09.725714Z"
        },
        "id": "27bb1148-0f61-48ed-ad9d-aa423902749f"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "2- Decision Tree Regressor"
      ],
      "metadata": {
        "id": "5b46497d-4d64-4604-a63e-6215aa363bc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DTRsmall_users = np.random.choice(tuning_groups.unique(), size=5000, replace=False)\n",
        "mask = tuning_groups.isin(DTRsmall_users)\n",
        "\n",
        "DTR_x_small = tuning_xr.loc[mask].copy()\n",
        "DTR_y_small = tuning_yr.loc[mask].copy()\n",
        "DTR_groups_small = tuning_groups.loc[mask].copy()\n",
        "\n",
        "\n",
        "DTR_pipline = make_pipeline(\n",
        "    preprocessor_reg ,\n",
        "    DecisionTreeRegressor(random_state = 42)\n",
        ")\n",
        "\n",
        "DTRparam_grid = {\n",
        "    \"decisiontreeregressor__max_depth\": [None , 10 , 20 , 30] ,\n",
        "    \"decisiontreeregressor__min_samples_split\": [2 , 10 , 20] ,\n",
        "    \"decisiontreeregressor__min_samples_leaf\": [1 , 10 , 50] ,\n",
        "}\n",
        "\n",
        "DTR_grid_search = GridSearchCV(\n",
        "    estimator = DTR_pipline ,\n",
        "    param_grid = DTRparam_grid ,\n",
        "    cv = GF ,\n",
        "    scoring = \"r2\" ,\n",
        "    n_jobs = -1\n",
        ")\n",
        "\n",
        "DTR_grid_search.fit(DTR_x_small, DTR_y_small, groups = DTR_groups_small)\n",
        "\n",
        "print(\"\\nBest Score:\" , DTR_grid_search.best_score_)\n",
        "print(\"Best Parameters:\" , DTR_grid_search.best_params_)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T12:53:27.834915Z",
          "iopub.execute_input": "2025-12-26T12:53:27.835645Z",
          "iopub.status.idle": "2025-12-26T12:54:35.871334Z",
          "shell.execute_reply.started": "2025-12-26T12:53:27.835614Z",
          "shell.execute_reply": "2025-12-26T12:54:35.870515Z"
        },
        "id": "857678d9-983d-4619-b47e-2182422d5596"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "best_RMD = DTR_grid_search.best_params_[\"decisiontreeregressor__max_depth\"]\n",
        "best_RMSS = DTR_grid_search.best_params_[ \"decisiontreeregressor__min_samples_split\"]\n",
        "best_RMSL = DTR_grid_search.best_params_[\"decisiontreeregressor__min_samples_leaf\"]\n",
        "\n",
        "final_DTR_pip = make_pipeline(\n",
        "    preprocessor_reg ,\n",
        "    DecisionTreeRegressor(max_depth = best_RMD , min_samples_leaf = best_RMSL ,\n",
        "                           min_samples_split = best_RMSS , random_state = 42)\n",
        ")\n",
        "model_score(final_DTR_pip , xr_train , yr_train , xr_test , yr_test)\n",
        "#قبل تعديل السبلت\n",
        "# MAE:  5.257224113534276\n",
        "# RMSE: 7.805453685792402\n",
        "# R2:   0.3730198334737874\n",
        " #بعد التعديل\n",
        "# MAE:  4.69943136062894\n",
        "# RMSE: 6.862364731848102\n",
        "# R2:   0.5153758030454685"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T13:23:03.253109Z",
          "iopub.execute_input": "2025-12-26T13:23:03.254083Z",
          "iopub.status.idle": "2025-12-26T13:23:07.202204Z",
          "shell.execute_reply.started": "2025-12-26T13:23:03.254045Z",
          "shell.execute_reply": "2025-12-26T13:23:07.201419Z"
        },
        "id": "edc69ce3-abc1-404c-ac4c-a7f39616ca27"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#هاي ممكن تحذفها او تزبطها تخليها قلت لشات يجيب السكور للثنين بس ونشوف الفرق بينهم\n",
        "\n",
        "\n",
        "# print(\"Checking for Overfitting...\")\n",
        "\n",
        "# # احسب سكور التدريب\n",
        "# train_score = final_DTR_pip.score(xr_train, yr_train)\n",
        "# print(f\"Training R2 Score: {train_score:.4f}\")\n",
        "\n",
        "# # احسب سكور التست (اللي طلع معك)\n",
        "# test_score = final_DTR_pip.score(xr_test, yr_test)\n",
        "# print(f\"Test R2 Score:     {test_score:.4f}\")\n",
        "\n",
        "# diff = train_score - test_score\n",
        "# print(f\"Difference:        {diff:.4f}\")\n",
        "\n",
        "# if diff > 0.15:\n",
        "#     print(\"⚠️ Warning: Possible Overfitting\")\n",
        "# else:\n",
        "#     print(\"✅ Excellent! No Overfitting detected.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-26T13:23:07.848366Z",
          "iopub.execute_input": "2025-12-26T13:23:07.848696Z",
          "iopub.status.idle": "2025-12-26T13:23:08.602754Z",
          "shell.execute_reply.started": "2025-12-26T13:23:07.848667Z",
          "shell.execute_reply": "2025-12-26T13:23:08.601765Z"
        },
        "id": "58124c28-a22b-4988-a0b0-2efe8d7f6096"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "495ba009-1b04-4008-8c5a-96ab76137fc5"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}